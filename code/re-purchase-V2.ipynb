{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK8MOo9XEnJ-"
   },
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据、观察数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CS__iAo4El3Z"
   },
   "outputs": [],
   "source": [
    "# 加载全量样本\n",
    "# user_log = pd.read_csv('./data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "# user_info = pd.read_csv('./data_format1/user_info_format1.csv')\n",
    "# train_data1 = pd.read_csv('./data_format1/train_format1.csv')\n",
    "# submission = pd.read_csv('./data_format1/test_format1.csv')\n",
    "# train_data = pd.read_csv('./data_format2/train_format2.csv')\n",
    "\n",
    "'''\n",
    "train_format1：数据集中只包含 label为0和1的数据。\n",
    "train_format2：数据集中同时包含 label为0、1和-1的数据。\n",
    "user_info_format1：用户信息数据集。\n",
    "user_log_format1：用户日志数据集。\n",
    "'''\n",
    "\n",
    "# 文件路径\n",
    "filePath = \"../data\"\n",
    "\n",
    "# 导入数据\n",
    "df_train1 = pd.read_csv(filePath + os.sep + 'data_format1' + os.sep + 'train_format1.csv', encoding='ISO-8859-1')\n",
    "df_train2 = pd.read_csv(filePath + os.sep + 'data_format2' + os.sep + 'train_format2.csv', encoding='ISO-8859-1')\n",
    "df_test1 = pd.read_csv(filePath + os.sep + 'data_format1' + os.sep + 'test_format1.csv', encoding='ISO-8859-1')\n",
    "df_test2 = pd.read_csv(filePath + os.sep + 'data_format2' + os.sep + 'test_format2.csv', encoding='ISO-8859-1')\n",
    "df_user_info = pd.read_csv(filePath + os.sep + 'data_format1' + os.sep + 'user_info_format1.csv', encoding='ISO-8859-1')\n",
    "df_user_log = pd.read_csv(filePath + os.sep + 'data_format1' + os.sep + 'user_log_format1.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train1 shape:  (260864, 3) Index(['user_id', 'merchant_id', 'label'], dtype='object')\n",
      "df_train2 shape:  (7030723, 6) Index(['user_id', 'age_range', 'gender', 'merchant_id', 'label',\n",
      "       'activity_log'],\n",
      "      dtype='object')\n",
      "df_test1 shape:  (261477, 3) Index(['user_id', 'merchant_id', 'prob'], dtype='object')\n",
      "df_test2 shape:  (7027943, 6) Index(['user_id', 'age_range', 'gender', 'merchant_id', 'label',\n",
      "       'activity_log'],\n",
      "      dtype='object')\n",
      "df_user_info shape:  (424170, 3) Index(['user_id', 'age_range', 'gender'], dtype='object')\n",
      "df_user_log shape:  (54925330, 7) Index(['user_id', 'item_id', 'cat_id', 'seller_id', 'brand_id', 'time_stamp',\n",
      "       'action_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 查看数据规模\n",
    "# print('----------数据集规模-------------')\n",
    "print('df_train1 shape: ', df_train1.shape, df_train1.columns)\n",
    "print('df_train2 shape: ', df_train2.shape, df_train2.columns)\n",
    "print('df_test1 shape: ', df_test1.shape, df_test1.columns)\n",
    "print('df_test2 shape: ', df_test2.shape, df_test2.columns)\n",
    "print('df_user_info shape: ', df_user_info.shape, df_user_info.columns)\n",
    "print('df_user_log shape: ', df_user_log.shape, df_user_log.columns)\n",
    "\n",
    "# 查看数据大体情况\n",
    "# print('-----------数据集字段-------------')\n",
    "# print('df_train1 head: \\n', df_train1.head())\n",
    "# print('df_train2 head: \\n', df_train2.head())\n",
    "# print('df_test1 head: \\n', df_test1.head())\n",
    "# print('df_test2 head: \\n', df_test2.head())\n",
    "# print('df_user_info head: \\n', df_user_info.head())\n",
    "# print('df_user_log head: \\n', df_user_log.head())\n",
    "\n",
    "# 查看是否有缺失值\n",
    "# print(df_train1.info(verbose=True,null_counts=True))\n",
    "# print(df_train2.info(verbose=True,null_counts=True))\n",
    "# print(df_test1.info(verbose=True,null_counts=True))\n",
    "# print(df_test2.info(verbose=True,null_counts=True))\n",
    "# print(df_user_info.info(verbose=True,null_counts=True))\n",
    "# print(df_user_log.info(verbose=True,null_counts=True))\n",
    "\n",
    "# 特殊值查看\n",
    "# print('df_train1 label: \\n', df_train1['label'].value_counts())\n",
    "# print('df_train2 label: \\n', df_train2['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ef_iyJIWQyUL"
   },
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1843,
     "status": "ok",
     "timestamp": 1591454889879,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "PvqmPMtYP1tn",
    "outputId": "7295a1fb-c581-495f-e77f-b79dc1afd34a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id  label origin  age_range  gender\n",
       "0         34176         3906    0.0  train        6.0     0.0\n",
       "1         34176          121    0.0  train        6.0     0.0\n",
       "2         34176         4356    1.0  train        6.0     0.0\n",
       "3         34176         2217    0.0  train        6.0     0.0\n",
       "4        230784         4818    0.0  train        0.0     0.0\n",
       "...         ...          ...    ...    ...        ...     ...\n",
       "522336   228479         3111    NaN   test        6.0     0.0\n",
       "522337    97919         2341    NaN   test        8.0     1.0\n",
       "522338    97919         3971    NaN   test        8.0     1.0\n",
       "522339    32639         3536    NaN   test        0.0     0.0\n",
       "522340    32639         3319    NaN   test        0.0     0.0\n",
       "\n",
       "[522341 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1['origin'] = 'train'\n",
    "df_test1['origin'] = 'test'\n",
    "matrix = pd.concat([df_train1, df_test1], ignore_index=True, sort=False)\n",
    "matrix.drop(['prob'], axis=1, inplace=True)\n",
    "# 连接user_info表，通过user_id关联\n",
    "matrix = matrix.merge(df_user_info, on='user_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9340,
     "status": "ok",
     "timestamp": 1591454901115,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "I91QWtqjsT9M",
    "outputId": "0805b96c-8bad-400a-e766-1ddb5073838a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender\n",
       "0         34176         3906   0.0  train          6       0\n",
       "1         34176          121   0.0  train          6       0\n",
       "2         34176         4356   1.0  train          6       0\n",
       "3         34176         2217   0.0  train          6       0\n",
       "4        230784         4818   0.0  train          0       0\n",
       "...         ...          ...   ...    ...        ...     ...\n",
       "522336   228479         3111   nan   test          6       0\n",
       "522337    97919         2341   nan   test          8       1\n",
       "522338    97919         3971   nan   test          8       1\n",
       "522339    32639         3536   nan   test          0       0\n",
       "522340    32639         3319   nan   test          0       0\n",
       "\n",
       "[522341 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格式化\n",
    "df_user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)  # 使用merchant_id（原列名seller_id）\n",
    "df_user_log['user_id'] = df_user_log['user_id'].astype('int32')\n",
    "df_user_log['merchant_id'] = df_user_log['merchant_id'].astype('int32')\n",
    "df_user_log['item_id'] = df_user_log['item_id'].astype('int32')\n",
    "df_user_log['cat_id'] = df_user_log['cat_id'].astype('int32')\n",
    "df_user_log['brand_id'].fillna(0, inplace=True)\n",
    "df_user_log['brand_id'] = df_user_log['brand_id'].astype('int32')\n",
    "df_user_log['time_stamp'] = pd.to_datetime(df_user_log['time_stamp'], format='%H%M')\n",
    "\n",
    "matrix['age_range'].fillna(0, inplace=True)  # 0 and NULL for unknown\n",
    "matrix['gender'].fillna(2, inplace=True)  # 2 and NULL:unknown\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GVaAPE1tMcL"
   },
   "source": [
    "### 特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 293983,
     "status": "ok",
     "timestamp": 1591455200167,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "RYp92CpBqxwE",
    "outputId": "282edd98-537a-459d-807b-4b2394156f32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-dd6fd53dca45>:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>u5</th>\n",
       "      <th>u6</th>\n",
       "      <th>u7</th>\n",
       "      <th>u8</th>\n",
       "      <th>u9</th>\n",
       "      <th>u10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>282</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4   u5        u6      u7   u8    u9    u10  \n",
       "0       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "1       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "2       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "3       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "4        20   19  5.166667    47.0  NaN   7.0    NaN  \n",
       "...     ...  ...       ...     ...  ...   ...    ...  \n",
       "522336  278  282  6.000000  1770.0  NaN  26.0  208.0  \n",
       "522337   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
       "522338   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
       "522339   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
       "522340   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
       "\n",
       "[522341 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User特征处理\n",
    "groups = df_user_log.groupby(['user_id'])\n",
    "\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "\n",
    "# 统计操作类型为0，1，2，3的个数，0表示单击，1表示添加到购物车，2表示购买，3表示添加到收藏夹\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292602,
     "status": "ok",
     "timestamp": 1591455959081,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "tDMRmoowtUkD",
    "outputId": "85cf6bc9-490f-4e28-b17e-49f851e7e449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-407fe9f3798f>:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>...</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>m10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>16269</td>\n",
       "      <td>5819</td>\n",
       "      <td>308</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14870.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>79865</td>\n",
       "      <td>10931</td>\n",
       "      <td>1179</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>72265.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4780.0</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>7269</td>\n",
       "      <td>2281</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>60202</td>\n",
       "      <td>16870</td>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52230.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>48089</td>\n",
       "      <td>7500</td>\n",
       "      <td>461</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>43268.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>10105</td>\n",
       "      <td>4154</td>\n",
       "      <td>542</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>5543</td>\n",
       "      <td>1592</td>\n",
       "      <td>352</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>28892</td>\n",
       "      <td>7587</td>\n",
       "      <td>272</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>24602.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>14027</td>\n",
       "      <td>4956</td>\n",
       "      <td>322</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>12807.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>25959</td>\n",
       "      <td>7927</td>\n",
       "      <td>952</td>\n",
       "      <td>175</td>\n",
       "      <td>85</td>\n",
       "      <td>21737.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4  ...     m1     m2    m3   m4  m5       m6     m7      m8      m9  \\\n",
       "0       109  ...  16269   5819   308   20   2  14870.0   28.0   410.0   961.0   \n",
       "1       109  ...  79865  10931  1179   26   2  72265.0  121.0  4780.0  2699.0   \n",
       "2       109  ...   7269   2281    67   15   2   6094.0   16.0   963.0   196.0   \n",
       "3       109  ...  60202  16870   377    5   2  52230.0  101.0  3721.0  4150.0   \n",
       "4        20  ...  48089   7500   461   27   2  43268.0  129.0  2733.0  1959.0   \n",
       "...     ...  ...    ...    ...   ...  ...  ..      ...    ...     ...     ...   \n",
       "522336  278  ...  10105   4154   542   50  18   8997.0    9.0   687.0   412.0   \n",
       "522337   17  ...   5543   1592   352   93  19   4548.0    6.0   815.0   174.0   \n",
       "522338   17  ...  28892   7587   272    7   2  24602.0   94.0  2608.0  1588.0   \n",
       "522339   33  ...  14027   4956   322   19   3  12807.0   29.0   793.0   398.0   \n",
       "522340   33  ...  25959   7927   952  175  85  21737.0   34.0  2700.0  1488.0   \n",
       "\n",
       "         m10  \n",
       "0       2861  \n",
       "1       4530  \n",
       "2       1088  \n",
       "3       7268  \n",
       "4       3102  \n",
       "...      ...  \n",
       "522336  1982  \n",
       "522337   703  \n",
       "522338  3050  \n",
       "522339  2177  \n",
       "522340  3607  \n",
       "\n",
       "[522341 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 商家特征处理\n",
    "groups = df_user_log.groupby(['merchant_id'])\n",
    "\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的action_type 唯一值，0表示单击，1表示添加到购物车，2表示购买，3表示添加到收藏夹\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = df_train2[df_train2['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 372486,
     "status": "ok",
     "timestamp": 1591456597555,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "tAITQ6nhtiuB",
    "outputId": "4cd7d968-c510-45cc-94ec-d3e34bd10800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-5c07bfe4efb6>:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>...</th>\n",
       "      <th>m10</th>\n",
       "      <th>um1</th>\n",
       "      <th>um2</th>\n",
       "      <th>um3</th>\n",
       "      <th>um4</th>\n",
       "      <th>um5</th>\n",
       "      <th>um6</th>\n",
       "      <th>um7</th>\n",
       "      <th>um8</th>\n",
       "      <th>um9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>2861</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>4530</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1088</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>7268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>3102</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>1982</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3050</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>2177</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>3607</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4  ...   m10  um1  um2  um3  um4   um5  um6  um7  um8       um9  \n",
       "0       109  ...  2861   39   20    6    1  36.0  NaN  1.0  2.0  0.850000  \n",
       "1       109  ...  4530   14    1    1    1  13.0  NaN  1.0  NaN  0.050000  \n",
       "2       109  ...  1088   18    2    1    1  12.0  NaN  6.0  NaN  0.016667  \n",
       "3       109  ...  7268    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
       "4        20  ...  3102    8    1    1    1   7.0  NaN  1.0  NaN  0.050000  \n",
       "...     ...  ...   ...  ...  ...  ...  ...   ...  ...  ...  ...       ...  \n",
       "522336  278  ...  1982    5    2    1    1   4.0  NaN  1.0  NaN  0.016667  \n",
       "522337   17  ...   703    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
       "522338   17  ...  3050   16    5    2    1  12.0  NaN  4.0  NaN  0.150000  \n",
       "522339   33  ...  2177    3    2    1    1   2.0  NaN  1.0  NaN  0.000000  \n",
       "522340   33  ...  3607   11    1    1    1  10.0  NaN  1.0  NaN  0.016667  \n",
       "\n",
       "[522341 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照user_id, merchant_id分组\n",
    "groups = df_user_log.groupby(['user_id', 'merchant_id'])\n",
    "\n",
    "# 统计行为个数\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'})\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计item_id, cat_id, brand_id唯一个数\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'})\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计不同action_type唯一个数\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计时间间隔\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1591457123542,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "FkhtndxqtmqH",
    "outputId": "7667d7e6-3a2d-4a03-ec94-8c9161ab0b90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>u5</th>\n",
       "      <th>u6</th>\n",
       "      <th>...</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>age_8</th>\n",
       "      <th>g_0</th>\n",
       "      <th>g_1</th>\n",
       "      <th>g_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>282</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin    u1    u2  u3   u4   u5        u6  \\\n",
       "0         34176         3906   0.0  train   451   256  45  109  108  5.833333   \n",
       "1         34176          121   0.0  train   451   256  45  109  108  5.833333   \n",
       "2         34176         4356   1.0  train   451   256  45  109  108  5.833333   \n",
       "3         34176         2217   0.0  train   451   256  45  109  108  5.833333   \n",
       "4        230784         4818   0.0  train    54    31  17   20   19  5.166667   \n",
       "...         ...          ...   ...    ...   ...   ...  ..  ...  ...       ...   \n",
       "522336   228479         3111   nan   test  2004  1173  71  278  282  6.000000   \n",
       "522337    97919         2341   nan   test    55    29  14   17   17  4.750000   \n",
       "522338    97919         3971   nan   test    55    29  14   17   17  4.750000   \n",
       "522339    32639         3536   nan   test    72    46  24   33   35  5.800000   \n",
       "522340    32639         3319   nan   test    72    46  24   33   35  5.800000   \n",
       "\n",
       "        ...  age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
       "0       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "1       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "2       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "3       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "4       ...      0      0      0      0      0      0      0    1    0    0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
       "522336  ...      0      0      0      0      1      0      0    1    0    0  \n",
       "522337  ...      0      0      0      0      0      0      1    0    1    0  \n",
       "522338  ...      0      0      0      0      0      0      1    0    1    0  \n",
       "522339  ...      0      0      0      0      0      0      0    1    0    0  \n",
       "522340  ...      0      0      0      0      0      0      0    1    0    0  \n",
       "\n",
       "[522341 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "\n",
    "# 商家购买点击比 不需要这个特征值，得分0.68\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "\n",
    "# 不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "\n",
    "# 填充缺失值\n",
    "matrix.fillna(0, inplace=True)\n",
    "\n",
    "# 采用one-hot编码 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "\n",
    "# 采用one-hot编码 修改gender字段名称为 g_0, g_1, g_2\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "\n",
    "# 删除age_range, gender字段\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h5CH5C2tuzu"
   },
   "source": [
    "### 训练集和测试集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1591457129198,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "CnYNZFoGttxN",
    "outputId": "80dc95ff-7d37-4357-c197-2b9255699fd1"
   },
   "outputs": [],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_LRyu0at1GM"
   },
   "source": [
    "### 模型训练（传统模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQUqgaI-BotK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入用到的模型包\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "# 将训练集进行切分，20%用于验证\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14083,
     "status": "ok",
     "timestamp": 1591454613098,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "_ufmBEx4uVo_",
    "outputId": "df9d8671-1a1c-4dc8-f35e-b584bbe46ab8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63843\tvalidation_1-auc:0.63494\n",
      "[1]\tvalidation_0-auc:0.65090\tvalidation_1-auc:0.64856\n",
      "[2]\tvalidation_0-auc:0.65673\tvalidation_1-auc:0.65008\n",
      "[3]\tvalidation_0-auc:0.66078\tvalidation_1-auc:0.65144\n",
      "[4]\tvalidation_0-auc:0.66146\tvalidation_1-auc:0.65206\n",
      "[5]\tvalidation_0-auc:0.66345\tvalidation_1-auc:0.65174\n",
      "[6]\tvalidation_0-auc:0.66562\tvalidation_1-auc:0.65225\n",
      "[7]\tvalidation_0-auc:0.66700\tvalidation_1-auc:0.65530\n",
      "[8]\tvalidation_0-auc:0.66797\tvalidation_1-auc:0.65673\n",
      "[9]\tvalidation_0-auc:0.66997\tvalidation_1-auc:0.65852\n",
      "[10]\tvalidation_0-auc:0.67204\tvalidation_1-auc:0.66006\n",
      "[11]\tvalidation_0-auc:0.67254\tvalidation_1-auc:0.66038\n",
      "[12]\tvalidation_0-auc:0.67372\tvalidation_1-auc:0.66052\n",
      "[13]\tvalidation_0-auc:0.67571\tvalidation_1-auc:0.66108\n",
      "[14]\tvalidation_0-auc:0.67894\tvalidation_1-auc:0.66416\n",
      "[15]\tvalidation_0-auc:0.68118\tvalidation_1-auc:0.66506\n",
      "[16]\tvalidation_0-auc:0.68285\tvalidation_1-auc:0.66573\n",
      "[17]\tvalidation_0-auc:0.68388\tvalidation_1-auc:0.66513\n",
      "[18]\tvalidation_0-auc:0.68586\tvalidation_1-auc:0.66705\n",
      "[19]\tvalidation_0-auc:0.68780\tvalidation_1-auc:0.67006\n",
      "[20]\tvalidation_0-auc:0.68872\tvalidation_1-auc:0.67000\n",
      "[21]\tvalidation_0-auc:0.69024\tvalidation_1-auc:0.67085\n",
      "[22]\tvalidation_0-auc:0.69153\tvalidation_1-auc:0.67167\n",
      "[23]\tvalidation_0-auc:0.69253\tvalidation_1-auc:0.67174\n",
      "[24]\tvalidation_0-auc:0.69282\tvalidation_1-auc:0.67228\n",
      "[25]\tvalidation_0-auc:0.69390\tvalidation_1-auc:0.67229\n",
      "[26]\tvalidation_0-auc:0.69470\tvalidation_1-auc:0.67292\n",
      "[27]\tvalidation_0-auc:0.69523\tvalidation_1-auc:0.67253\n",
      "[28]\tvalidation_0-auc:0.69621\tvalidation_1-auc:0.67227\n",
      "[29]\tvalidation_0-auc:0.69745\tvalidation_1-auc:0.67282\n",
      "[30]\tvalidation_0-auc:0.69826\tvalidation_1-auc:0.67291\n",
      "[31]\tvalidation_0-auc:0.69908\tvalidation_1-auc:0.67255\n",
      "[32]\tvalidation_0-auc:0.69969\tvalidation_1-auc:0.67264\n",
      "[33]\tvalidation_0-auc:0.70051\tvalidation_1-auc:0.67258\n",
      "[34]\tvalidation_0-auc:0.70114\tvalidation_1-auc:0.67311\n",
      "[35]\tvalidation_0-auc:0.70189\tvalidation_1-auc:0.67340\n",
      "[36]\tvalidation_0-auc:0.70294\tvalidation_1-auc:0.67394\n",
      "[37]\tvalidation_0-auc:0.70359\tvalidation_1-auc:0.67345\n",
      "[38]\tvalidation_0-auc:0.70417\tvalidation_1-auc:0.67327\n",
      "[39]\tvalidation_0-auc:0.70525\tvalidation_1-auc:0.67322\n",
      "[40]\tvalidation_0-auc:0.70601\tvalidation_1-auc:0.67323\n",
      "[41]\tvalidation_0-auc:0.70667\tvalidation_1-auc:0.67306\n",
      "[42]\tvalidation_0-auc:0.70774\tvalidation_1-auc:0.67436\n",
      "[43]\tvalidation_0-auc:0.70839\tvalidation_1-auc:0.67467\n",
      "[44]\tvalidation_0-auc:0.70918\tvalidation_1-auc:0.67561\n",
      "[45]\tvalidation_0-auc:0.71015\tvalidation_1-auc:0.67586\n",
      "[46]\tvalidation_0-auc:0.71090\tvalidation_1-auc:0.67577\n",
      "[47]\tvalidation_0-auc:0.71158\tvalidation_1-auc:0.67583\n",
      "[48]\tvalidation_0-auc:0.71251\tvalidation_1-auc:0.67599\n",
      "[49]\tvalidation_0-auc:0.71295\tvalidation_1-auc:0.67607\n",
      "[50]\tvalidation_0-auc:0.71352\tvalidation_1-auc:0.67614\n",
      "[51]\tvalidation_0-auc:0.71404\tvalidation_1-auc:0.67669\n",
      "[52]\tvalidation_0-auc:0.71460\tvalidation_1-auc:0.67657\n",
      "[53]\tvalidation_0-auc:0.71522\tvalidation_1-auc:0.67659\n",
      "[54]\tvalidation_0-auc:0.71596\tvalidation_1-auc:0.67660\n",
      "[55]\tvalidation_0-auc:0.71647\tvalidation_1-auc:0.67671\n",
      "[56]\tvalidation_0-auc:0.71711\tvalidation_1-auc:0.67681\n",
      "[57]\tvalidation_0-auc:0.71782\tvalidation_1-auc:0.67693\n",
      "[58]\tvalidation_0-auc:0.71826\tvalidation_1-auc:0.67705\n",
      "[59]\tvalidation_0-auc:0.71845\tvalidation_1-auc:0.67742\n",
      "[60]\tvalidation_0-auc:0.71869\tvalidation_1-auc:0.67697\n",
      "[61]\tvalidation_0-auc:0.71928\tvalidation_1-auc:0.67701\n",
      "[62]\tvalidation_0-auc:0.71936\tvalidation_1-auc:0.67710\n",
      "[63]\tvalidation_0-auc:0.71976\tvalidation_1-auc:0.67711\n",
      "[64]\tvalidation_0-auc:0.72026\tvalidation_1-auc:0.67679\n",
      "[65]\tvalidation_0-auc:0.72100\tvalidation_1-auc:0.67637\n",
      "[66]\tvalidation_0-auc:0.72123\tvalidation_1-auc:0.67633\n",
      "[67]\tvalidation_0-auc:0.72161\tvalidation_1-auc:0.67601\n",
      "[68]\tvalidation_0-auc:0.72235\tvalidation_1-auc:0.67583\n",
      "[13:59:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eta=0.3, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=300, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=80, num_parallel_tree=1,\n",
       "              random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=42, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42     \n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='auc', \n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=True,\n",
    "    #早停法，如果auc在10epoch没有进步就stop\n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90922,
     "status": "ok",
     "timestamp": 1591457231215,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "zZ0s2nxRDbIq",
    "outputId": "1ca6b7b0-faed-447f-97c2-812324c8f19c",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.634596\ttraining's binary_logloss: 0.230818\tvalid_1's auc: 0.629549\tvalid_1's binary_logloss: 0.225874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.650092\ttraining's binary_logloss: 0.230509\tvalid_1's auc: 0.643262\tvalid_1's binary_logloss: 0.225599\n",
      "[3]\ttraining's auc: 0.655061\ttraining's binary_logloss: 0.230191\tvalid_1's auc: 0.648012\tvalid_1's binary_logloss: 0.225324\n",
      "[4]\ttraining's auc: 0.657688\ttraining's binary_logloss: 0.229904\tvalid_1's auc: 0.647796\tvalid_1's binary_logloss: 0.225085\n",
      "[5]\ttraining's auc: 0.659129\ttraining's binary_logloss: 0.229628\tvalid_1's auc: 0.648493\tvalid_1's binary_logloss: 0.224835\n",
      "[6]\ttraining's auc: 0.659982\ttraining's binary_logloss: 0.229365\tvalid_1's auc: 0.648319\tvalid_1's binary_logloss: 0.224604\n",
      "[7]\ttraining's auc: 0.660836\ttraining's binary_logloss: 0.229102\tvalid_1's auc: 0.64961\tvalid_1's binary_logloss: 0.224373\n",
      "[8]\ttraining's auc: 0.66131\ttraining's binary_logloss: 0.228844\tvalid_1's auc: 0.65091\tvalid_1's binary_logloss: 0.224141\n",
      "[9]\ttraining's auc: 0.662414\ttraining's binary_logloss: 0.228601\tvalid_1's auc: 0.65244\tvalid_1's binary_logloss: 0.223927\n",
      "[10]\ttraining's auc: 0.662052\ttraining's binary_logloss: 0.228361\tvalid_1's auc: 0.652261\tvalid_1's binary_logloss: 0.223711\n",
      "[11]\ttraining's auc: 0.663296\ttraining's binary_logloss: 0.22813\tvalid_1's auc: 0.652811\tvalid_1's binary_logloss: 0.223515\n",
      "[12]\ttraining's auc: 0.664016\ttraining's binary_logloss: 0.227902\tvalid_1's auc: 0.653444\tvalid_1's binary_logloss: 0.223312\n",
      "[13]\ttraining's auc: 0.664707\ttraining's binary_logloss: 0.22769\tvalid_1's auc: 0.654073\tvalid_1's binary_logloss: 0.223122\n",
      "[14]\ttraining's auc: 0.665386\ttraining's binary_logloss: 0.227481\tvalid_1's auc: 0.654204\tvalid_1's binary_logloss: 0.222945\n",
      "[15]\ttraining's auc: 0.666208\ttraining's binary_logloss: 0.227279\tvalid_1's auc: 0.654849\tvalid_1's binary_logloss: 0.222768\n",
      "[16]\ttraining's auc: 0.667923\ttraining's binary_logloss: 0.227071\tvalid_1's auc: 0.656846\tvalid_1's binary_logloss: 0.222577\n",
      "[17]\ttraining's auc: 0.668181\ttraining's binary_logloss: 0.226875\tvalid_1's auc: 0.656909\tvalid_1's binary_logloss: 0.222403\n",
      "[18]\ttraining's auc: 0.668617\ttraining's binary_logloss: 0.226675\tvalid_1's auc: 0.657055\tvalid_1's binary_logloss: 0.222232\n",
      "[19]\ttraining's auc: 0.669101\ttraining's binary_logloss: 0.226505\tvalid_1's auc: 0.657036\tvalid_1's binary_logloss: 0.222094\n",
      "[20]\ttraining's auc: 0.669144\ttraining's binary_logloss: 0.226311\tvalid_1's auc: 0.657378\tvalid_1's binary_logloss: 0.221929\n",
      "[21]\ttraining's auc: 0.668921\ttraining's binary_logloss: 0.226135\tvalid_1's auc: 0.657214\tvalid_1's binary_logloss: 0.221788\n",
      "[22]\ttraining's auc: 0.66885\ttraining's binary_logloss: 0.225967\tvalid_1's auc: 0.657409\tvalid_1's binary_logloss: 0.221642\n",
      "[23]\ttraining's auc: 0.669225\ttraining's binary_logloss: 0.225798\tvalid_1's auc: 0.657325\tvalid_1's binary_logloss: 0.221503\n",
      "[24]\ttraining's auc: 0.669529\ttraining's binary_logloss: 0.225636\tvalid_1's auc: 0.65765\tvalid_1's binary_logloss: 0.221357\n",
      "[25]\ttraining's auc: 0.669605\ttraining's binary_logloss: 0.225472\tvalid_1's auc: 0.657727\tvalid_1's binary_logloss: 0.221226\n",
      "[26]\ttraining's auc: 0.669715\ttraining's binary_logloss: 0.225311\tvalid_1's auc: 0.657658\tvalid_1's binary_logloss: 0.2211\n",
      "[27]\ttraining's auc: 0.669672\ttraining's binary_logloss: 0.225161\tvalid_1's auc: 0.6574\tvalid_1's binary_logloss: 0.220981\n",
      "[28]\ttraining's auc: 0.66959\ttraining's binary_logloss: 0.225013\tvalid_1's auc: 0.657078\tvalid_1's binary_logloss: 0.220867\n",
      "[29]\ttraining's auc: 0.669715\ttraining's binary_logloss: 0.224873\tvalid_1's auc: 0.657295\tvalid_1's binary_logloss: 0.220754\n",
      "[30]\ttraining's auc: 0.669936\ttraining's binary_logloss: 0.224733\tvalid_1's auc: 0.657202\tvalid_1's binary_logloss: 0.22065\n",
      "[31]\ttraining's auc: 0.670309\ttraining's binary_logloss: 0.224607\tvalid_1's auc: 0.657265\tvalid_1's binary_logloss: 0.22055\n",
      "[32]\ttraining's auc: 0.670786\ttraining's binary_logloss: 0.224462\tvalid_1's auc: 0.657232\tvalid_1's binary_logloss: 0.220441\n",
      "[33]\ttraining's auc: 0.670996\ttraining's binary_logloss: 0.22433\tvalid_1's auc: 0.657219\tvalid_1's binary_logloss: 0.220337\n",
      "[34]\ttraining's auc: 0.671475\ttraining's binary_logloss: 0.224193\tvalid_1's auc: 0.657666\tvalid_1's binary_logloss: 0.220221\n",
      "[35]\ttraining's auc: 0.671832\ttraining's binary_logloss: 0.22406\tvalid_1's auc: 0.657708\tvalid_1's binary_logloss: 0.220136\n",
      "[36]\ttraining's auc: 0.672136\ttraining's binary_logloss: 0.223933\tvalid_1's auc: 0.657626\tvalid_1's binary_logloss: 0.220048\n",
      "[37]\ttraining's auc: 0.672305\ttraining's binary_logloss: 0.223819\tvalid_1's auc: 0.657726\tvalid_1's binary_logloss: 0.21996\n",
      "[38]\ttraining's auc: 0.672881\ttraining's binary_logloss: 0.223691\tvalid_1's auc: 0.657971\tvalid_1's binary_logloss: 0.219864\n",
      "[39]\ttraining's auc: 0.673248\ttraining's binary_logloss: 0.223578\tvalid_1's auc: 0.65807\tvalid_1's binary_logloss: 0.219775\n",
      "[40]\ttraining's auc: 0.673343\ttraining's binary_logloss: 0.223461\tvalid_1's auc: 0.658038\tvalid_1's binary_logloss: 0.219684\n",
      "[41]\ttraining's auc: 0.673563\ttraining's binary_logloss: 0.223351\tvalid_1's auc: 0.658229\tvalid_1's binary_logloss: 0.219591\n",
      "[42]\ttraining's auc: 0.673947\ttraining's binary_logloss: 0.223235\tvalid_1's auc: 0.658469\tvalid_1's binary_logloss: 0.21951\n",
      "[43]\ttraining's auc: 0.674193\ttraining's binary_logloss: 0.223119\tvalid_1's auc: 0.658842\tvalid_1's binary_logloss: 0.219411\n",
      "[44]\ttraining's auc: 0.674511\ttraining's binary_logloss: 0.223011\tvalid_1's auc: 0.65907\tvalid_1's binary_logloss: 0.219324\n",
      "[45]\ttraining's auc: 0.675086\ttraining's binary_logloss: 0.222897\tvalid_1's auc: 0.659182\tvalid_1's binary_logloss: 0.219243\n",
      "[46]\ttraining's auc: 0.675338\ttraining's binary_logloss: 0.222793\tvalid_1's auc: 0.659513\tvalid_1's binary_logloss: 0.219156\n",
      "[47]\ttraining's auc: 0.675531\ttraining's binary_logloss: 0.222693\tvalid_1's auc: 0.659483\tvalid_1's binary_logloss: 0.219087\n",
      "[48]\ttraining's auc: 0.67583\ttraining's binary_logloss: 0.222592\tvalid_1's auc: 0.659596\tvalid_1's binary_logloss: 0.219011\n",
      "[49]\ttraining's auc: 0.67648\ttraining's binary_logloss: 0.222478\tvalid_1's auc: 0.660053\tvalid_1's binary_logloss: 0.218926\n",
      "[50]\ttraining's auc: 0.676811\ttraining's binary_logloss: 0.222374\tvalid_1's auc: 0.660195\tvalid_1's binary_logloss: 0.218848\n",
      "[51]\ttraining's auc: 0.677057\ttraining's binary_logloss: 0.222274\tvalid_1's auc: 0.660481\tvalid_1's binary_logloss: 0.218769\n",
      "[52]\ttraining's auc: 0.67728\ttraining's binary_logloss: 0.222173\tvalid_1's auc: 0.660569\tvalid_1's binary_logloss: 0.21869\n",
      "[53]\ttraining's auc: 0.677688\ttraining's binary_logloss: 0.222073\tvalid_1's auc: 0.661035\tvalid_1's binary_logloss: 0.218604\n",
      "[54]\ttraining's auc: 0.678074\ttraining's binary_logloss: 0.221974\tvalid_1's auc: 0.661321\tvalid_1's binary_logloss: 0.21853\n",
      "[55]\ttraining's auc: 0.678382\ttraining's binary_logloss: 0.221878\tvalid_1's auc: 0.66133\tvalid_1's binary_logloss: 0.218463\n",
      "[56]\ttraining's auc: 0.678831\ttraining's binary_logloss: 0.221775\tvalid_1's auc: 0.66171\tvalid_1's binary_logloss: 0.218375\n",
      "[57]\ttraining's auc: 0.679215\ttraining's binary_logloss: 0.221685\tvalid_1's auc: 0.661716\tvalid_1's binary_logloss: 0.218315\n",
      "[58]\ttraining's auc: 0.679499\ttraining's binary_logloss: 0.221598\tvalid_1's auc: 0.661844\tvalid_1's binary_logloss: 0.218251\n",
      "[59]\ttraining's auc: 0.679783\ttraining's binary_logloss: 0.221516\tvalid_1's auc: 0.662067\tvalid_1's binary_logloss: 0.218184\n",
      "[60]\ttraining's auc: 0.679926\ttraining's binary_logloss: 0.221436\tvalid_1's auc: 0.662047\tvalid_1's binary_logloss: 0.218128\n",
      "[61]\ttraining's auc: 0.680345\ttraining's binary_logloss: 0.221346\tvalid_1's auc: 0.662281\tvalid_1's binary_logloss: 0.218059\n",
      "[62]\ttraining's auc: 0.680583\ttraining's binary_logloss: 0.221267\tvalid_1's auc: 0.662412\tvalid_1's binary_logloss: 0.218002\n",
      "[63]\ttraining's auc: 0.680822\ttraining's binary_logloss: 0.221192\tvalid_1's auc: 0.662518\tvalid_1's binary_logloss: 0.217949\n",
      "[64]\ttraining's auc: 0.680934\ttraining's binary_logloss: 0.221126\tvalid_1's auc: 0.662569\tvalid_1's binary_logloss: 0.217899\n",
      "[65]\ttraining's auc: 0.681142\ttraining's binary_logloss: 0.221042\tvalid_1's auc: 0.662665\tvalid_1's binary_logloss: 0.217837\n",
      "[66]\ttraining's auc: 0.681273\ttraining's binary_logloss: 0.220959\tvalid_1's auc: 0.662687\tvalid_1's binary_logloss: 0.217774\n",
      "[67]\ttraining's auc: 0.681608\ttraining's binary_logloss: 0.220877\tvalid_1's auc: 0.662936\tvalid_1's binary_logloss: 0.217716\n",
      "[68]\ttraining's auc: 0.681985\ttraining's binary_logloss: 0.220789\tvalid_1's auc: 0.663193\tvalid_1's binary_logloss: 0.217657\n",
      "[69]\ttraining's auc: 0.682222\ttraining's binary_logloss: 0.220711\tvalid_1's auc: 0.663373\tvalid_1's binary_logloss: 0.217602\n",
      "[70]\ttraining's auc: 0.682843\ttraining's binary_logloss: 0.220626\tvalid_1's auc: 0.663659\tvalid_1's binary_logloss: 0.217547\n",
      "[71]\ttraining's auc: 0.683158\ttraining's binary_logloss: 0.220546\tvalid_1's auc: 0.663914\tvalid_1's binary_logloss: 0.217491\n",
      "[72]\ttraining's auc: 0.683384\ttraining's binary_logloss: 0.220467\tvalid_1's auc: 0.664105\tvalid_1's binary_logloss: 0.217429\n",
      "[73]\ttraining's auc: 0.683672\ttraining's binary_logloss: 0.220387\tvalid_1's auc: 0.664304\tvalid_1's binary_logloss: 0.217375\n",
      "[74]\ttraining's auc: 0.6838\ttraining's binary_logloss: 0.220316\tvalid_1's auc: 0.664433\tvalid_1's binary_logloss: 0.217331\n",
      "[75]\ttraining's auc: 0.684181\ttraining's binary_logloss: 0.22023\tvalid_1's auc: 0.66461\tvalid_1's binary_logloss: 0.217272\n",
      "[76]\ttraining's auc: 0.684495\ttraining's binary_logloss: 0.22015\tvalid_1's auc: 0.664871\tvalid_1's binary_logloss: 0.217211\n",
      "[77]\ttraining's auc: 0.684745\ttraining's binary_logloss: 0.220078\tvalid_1's auc: 0.664969\tvalid_1's binary_logloss: 0.21716\n",
      "[78]\ttraining's auc: 0.685004\ttraining's binary_logloss: 0.220006\tvalid_1's auc: 0.664975\tvalid_1's binary_logloss: 0.217115\n",
      "[79]\ttraining's auc: 0.685497\ttraining's binary_logloss: 0.219931\tvalid_1's auc: 0.665351\tvalid_1's binary_logloss: 0.217059\n",
      "[80]\ttraining's auc: 0.685716\ttraining's binary_logloss: 0.219867\tvalid_1's auc: 0.665292\tvalid_1's binary_logloss: 0.217027\n",
      "[81]\ttraining's auc: 0.685969\ttraining's binary_logloss: 0.219805\tvalid_1's auc: 0.665445\tvalid_1's binary_logloss: 0.216984\n",
      "[82]\ttraining's auc: 0.686137\ttraining's binary_logloss: 0.219747\tvalid_1's auc: 0.66549\tvalid_1's binary_logloss: 0.21695\n",
      "[83]\ttraining's auc: 0.686511\ttraining's binary_logloss: 0.219675\tvalid_1's auc: 0.665683\tvalid_1's binary_logloss: 0.216903\n",
      "[84]\ttraining's auc: 0.686842\ttraining's binary_logloss: 0.219611\tvalid_1's auc: 0.665789\tvalid_1's binary_logloss: 0.216864\n",
      "[85]\ttraining's auc: 0.687172\ttraining's binary_logloss: 0.219537\tvalid_1's auc: 0.666041\tvalid_1's binary_logloss: 0.216816\n",
      "[86]\ttraining's auc: 0.687479\ttraining's binary_logloss: 0.219466\tvalid_1's auc: 0.666319\tvalid_1's binary_logloss: 0.216765\n",
      "[87]\ttraining's auc: 0.687653\ttraining's binary_logloss: 0.219412\tvalid_1's auc: 0.666324\tvalid_1's binary_logloss: 0.216735\n",
      "[88]\ttraining's auc: 0.687963\ttraining's binary_logloss: 0.219341\tvalid_1's auc: 0.666611\tvalid_1's binary_logloss: 0.216683\n",
      "[89]\ttraining's auc: 0.688143\ttraining's binary_logloss: 0.219276\tvalid_1's auc: 0.666649\tvalid_1's binary_logloss: 0.216644\n",
      "[90]\ttraining's auc: 0.688422\ttraining's binary_logloss: 0.219211\tvalid_1's auc: 0.66678\tvalid_1's binary_logloss: 0.2166\n",
      "[91]\ttraining's auc: 0.688588\ttraining's binary_logloss: 0.219154\tvalid_1's auc: 0.66702\tvalid_1's binary_logloss: 0.216555\n",
      "[92]\ttraining's auc: 0.688861\ttraining's binary_logloss: 0.219089\tvalid_1's auc: 0.667218\tvalid_1's binary_logloss: 0.216515\n",
      "[93]\ttraining's auc: 0.689238\ttraining's binary_logloss: 0.219019\tvalid_1's auc: 0.667594\tvalid_1's binary_logloss: 0.216464\n",
      "[94]\ttraining's auc: 0.689383\ttraining's binary_logloss: 0.218965\tvalid_1's auc: 0.667572\tvalid_1's binary_logloss: 0.216433\n",
      "[95]\ttraining's auc: 0.68976\ttraining's binary_logloss: 0.218898\tvalid_1's auc: 0.667721\tvalid_1's binary_logloss: 0.216389\n",
      "[96]\ttraining's auc: 0.690071\ttraining's binary_logloss: 0.218836\tvalid_1's auc: 0.667889\tvalid_1's binary_logloss: 0.216349\n",
      "[97]\ttraining's auc: 0.69035\ttraining's binary_logloss: 0.218777\tvalid_1's auc: 0.668065\tvalid_1's binary_logloss: 0.21631\n",
      "[98]\ttraining's auc: 0.690573\ttraining's binary_logloss: 0.21872\tvalid_1's auc: 0.668142\tvalid_1's binary_logloss: 0.216281\n",
      "[99]\ttraining's auc: 0.690903\ttraining's binary_logloss: 0.218657\tvalid_1's auc: 0.668358\tvalid_1's binary_logloss: 0.216238\n",
      "[100]\ttraining's auc: 0.691068\ttraining's binary_logloss: 0.218604\tvalid_1's auc: 0.668392\tvalid_1's binary_logloss: 0.216208\n",
      "[101]\ttraining's auc: 0.69158\ttraining's binary_logloss: 0.218531\tvalid_1's auc: 0.668928\tvalid_1's binary_logloss: 0.216148\n",
      "[102]\ttraining's auc: 0.692083\ttraining's binary_logloss: 0.218463\tvalid_1's auc: 0.669315\tvalid_1's binary_logloss: 0.216101\n",
      "[103]\ttraining's auc: 0.692459\ttraining's binary_logloss: 0.218404\tvalid_1's auc: 0.66934\tvalid_1's binary_logloss: 0.216074\n",
      "[104]\ttraining's auc: 0.692802\ttraining's binary_logloss: 0.218349\tvalid_1's auc: 0.669338\tvalid_1's binary_logloss: 0.216053\n",
      "[105]\ttraining's auc: 0.692998\ttraining's binary_logloss: 0.218291\tvalid_1's auc: 0.66939\tvalid_1's binary_logloss: 0.216017\n",
      "[106]\ttraining's auc: 0.693216\ttraining's binary_logloss: 0.218237\tvalid_1's auc: 0.669463\tvalid_1's binary_logloss: 0.215988\n",
      "[107]\ttraining's auc: 0.693442\ttraining's binary_logloss: 0.218186\tvalid_1's auc: 0.669475\tvalid_1's binary_logloss: 0.215969\n",
      "[108]\ttraining's auc: 0.693665\ttraining's binary_logloss: 0.218136\tvalid_1's auc: 0.669426\tvalid_1's binary_logloss: 0.215956\n",
      "[109]\ttraining's auc: 0.694087\ttraining's binary_logloss: 0.218069\tvalid_1's auc: 0.669702\tvalid_1's binary_logloss: 0.215912\n",
      "[110]\ttraining's auc: 0.694377\ttraining's binary_logloss: 0.218012\tvalid_1's auc: 0.669855\tvalid_1's binary_logloss: 0.215877\n",
      "[111]\ttraining's auc: 0.694573\ttraining's binary_logloss: 0.217953\tvalid_1's auc: 0.669946\tvalid_1's binary_logloss: 0.21584\n",
      "[112]\ttraining's auc: 0.694708\ttraining's binary_logloss: 0.217901\tvalid_1's auc: 0.669935\tvalid_1's binary_logloss: 0.215812\n",
      "[113]\ttraining's auc: 0.694865\ttraining's binary_logloss: 0.217851\tvalid_1's auc: 0.669895\tvalid_1's binary_logloss: 0.215791\n",
      "[114]\ttraining's auc: 0.69513\ttraining's binary_logloss: 0.217799\tvalid_1's auc: 0.669912\tvalid_1's binary_logloss: 0.215767\n",
      "[115]\ttraining's auc: 0.695406\ttraining's binary_logloss: 0.217742\tvalid_1's auc: 0.670048\tvalid_1's binary_logloss: 0.215733\n",
      "[116]\ttraining's auc: 0.695644\ttraining's binary_logloss: 0.217696\tvalid_1's auc: 0.670081\tvalid_1's binary_logloss: 0.215711\n",
      "[117]\ttraining's auc: 0.696126\ttraining's binary_logloss: 0.21764\tvalid_1's auc: 0.670221\tvalid_1's binary_logloss: 0.215684\n",
      "[118]\ttraining's auc: 0.696555\ttraining's binary_logloss: 0.217586\tvalid_1's auc: 0.670407\tvalid_1's binary_logloss: 0.215656\n",
      "[119]\ttraining's auc: 0.6967\ttraining's binary_logloss: 0.217536\tvalid_1's auc: 0.670399\tvalid_1's binary_logloss: 0.215641\n",
      "[120]\ttraining's auc: 0.696916\ttraining's binary_logloss: 0.217491\tvalid_1's auc: 0.670476\tvalid_1's binary_logloss: 0.215619\n",
      "[121]\ttraining's auc: 0.697381\ttraining's binary_logloss: 0.217424\tvalid_1's auc: 0.670789\tvalid_1's binary_logloss: 0.215577\n",
      "[122]\ttraining's auc: 0.697802\ttraining's binary_logloss: 0.217362\tvalid_1's auc: 0.670969\tvalid_1's binary_logloss: 0.215538\n",
      "[123]\ttraining's auc: 0.698075\ttraining's binary_logloss: 0.217308\tvalid_1's auc: 0.671165\tvalid_1's binary_logloss: 0.215502\n",
      "[124]\ttraining's auc: 0.698328\ttraining's binary_logloss: 0.217252\tvalid_1's auc: 0.671389\tvalid_1's binary_logloss: 0.21546\n",
      "[125]\ttraining's auc: 0.69845\ttraining's binary_logloss: 0.217211\tvalid_1's auc: 0.671362\tvalid_1's binary_logloss: 0.215444\n",
      "[126]\ttraining's auc: 0.698638\ttraining's binary_logloss: 0.217167\tvalid_1's auc: 0.67137\tvalid_1's binary_logloss: 0.215429\n",
      "[127]\ttraining's auc: 0.698842\ttraining's binary_logloss: 0.217125\tvalid_1's auc: 0.671387\tvalid_1's binary_logloss: 0.215414\n",
      "[128]\ttraining's auc: 0.699038\ttraining's binary_logloss: 0.21708\tvalid_1's auc: 0.671399\tvalid_1's binary_logloss: 0.215393\n",
      "[129]\ttraining's auc: 0.699247\ttraining's binary_logloss: 0.217042\tvalid_1's auc: 0.671324\tvalid_1's binary_logloss: 0.215384\n",
      "[130]\ttraining's auc: 0.699457\ttraining's binary_logloss: 0.216998\tvalid_1's auc: 0.671348\tvalid_1's binary_logloss: 0.215365\n",
      "[131]\ttraining's auc: 0.699693\ttraining's binary_logloss: 0.216949\tvalid_1's auc: 0.671539\tvalid_1's binary_logloss: 0.215326\n",
      "[132]\ttraining's auc: 0.69991\ttraining's binary_logloss: 0.216904\tvalid_1's auc: 0.671654\tvalid_1's binary_logloss: 0.215303\n",
      "[133]\ttraining's auc: 0.700142\ttraining's binary_logloss: 0.216853\tvalid_1's auc: 0.67172\tvalid_1's binary_logloss: 0.215279\n",
      "[134]\ttraining's auc: 0.700273\ttraining's binary_logloss: 0.216811\tvalid_1's auc: 0.671715\tvalid_1's binary_logloss: 0.215261\n",
      "[135]\ttraining's auc: 0.700568\ttraining's binary_logloss: 0.216759\tvalid_1's auc: 0.671787\tvalid_1's binary_logloss: 0.215235\n",
      "[136]\ttraining's auc: 0.700748\ttraining's binary_logloss: 0.216711\tvalid_1's auc: 0.671806\tvalid_1's binary_logloss: 0.215216\n",
      "[137]\ttraining's auc: 0.700973\ttraining's binary_logloss: 0.216667\tvalid_1's auc: 0.671906\tvalid_1's binary_logloss: 0.215195\n",
      "[138]\ttraining's auc: 0.701209\ttraining's binary_logloss: 0.216627\tvalid_1's auc: 0.672021\tvalid_1's binary_logloss: 0.215176\n",
      "[139]\ttraining's auc: 0.70145\ttraining's binary_logloss: 0.216585\tvalid_1's auc: 0.672069\tvalid_1's binary_logloss: 0.215157\n",
      "[140]\ttraining's auc: 0.701639\ttraining's binary_logloss: 0.216544\tvalid_1's auc: 0.672086\tvalid_1's binary_logloss: 0.215148\n",
      "[141]\ttraining's auc: 0.701912\ttraining's binary_logloss: 0.216495\tvalid_1's auc: 0.672139\tvalid_1's binary_logloss: 0.21513\n",
      "[142]\ttraining's auc: 0.70219\ttraining's binary_logloss: 0.216448\tvalid_1's auc: 0.672216\tvalid_1's binary_logloss: 0.215106\n",
      "[143]\ttraining's auc: 0.702432\ttraining's binary_logloss: 0.216396\tvalid_1's auc: 0.672422\tvalid_1's binary_logloss: 0.215071\n",
      "[144]\ttraining's auc: 0.702614\ttraining's binary_logloss: 0.216355\tvalid_1's auc: 0.672526\tvalid_1's binary_logloss: 0.215047\n",
      "[145]\ttraining's auc: 0.702821\ttraining's binary_logloss: 0.216313\tvalid_1's auc: 0.672568\tvalid_1's binary_logloss: 0.215034\n",
      "[146]\ttraining's auc: 0.70301\ttraining's binary_logloss: 0.216273\tvalid_1's auc: 0.672612\tvalid_1's binary_logloss: 0.215017\n",
      "[147]\ttraining's auc: 0.703186\ttraining's binary_logloss: 0.216234\tvalid_1's auc: 0.672658\tvalid_1's binary_logloss: 0.215002\n",
      "[148]\ttraining's auc: 0.703569\ttraining's binary_logloss: 0.216183\tvalid_1's auc: 0.672851\tvalid_1's binary_logloss: 0.214976\n",
      "[149]\ttraining's auc: 0.703778\ttraining's binary_logloss: 0.216144\tvalid_1's auc: 0.672884\tvalid_1's binary_logloss: 0.214958\n",
      "[150]\ttraining's auc: 0.703989\ttraining's binary_logloss: 0.216101\tvalid_1's auc: 0.672967\tvalid_1's binary_logloss: 0.214938\n",
      "[151]\ttraining's auc: 0.704231\ttraining's binary_logloss: 0.216054\tvalid_1's auc: 0.673132\tvalid_1's binary_logloss: 0.21491\n",
      "[152]\ttraining's auc: 0.704499\ttraining's binary_logloss: 0.216003\tvalid_1's auc: 0.673331\tvalid_1's binary_logloss: 0.214874\n",
      "[153]\ttraining's auc: 0.704709\ttraining's binary_logloss: 0.215964\tvalid_1's auc: 0.673453\tvalid_1's binary_logloss: 0.214852\n",
      "[154]\ttraining's auc: 0.704955\ttraining's binary_logloss: 0.215924\tvalid_1's auc: 0.673388\tvalid_1's binary_logloss: 0.214848\n",
      "[155]\ttraining's auc: 0.705257\ttraining's binary_logloss: 0.215872\tvalid_1's auc: 0.673514\tvalid_1's binary_logloss: 0.214822\n",
      "[156]\ttraining's auc: 0.705424\ttraining's binary_logloss: 0.215834\tvalid_1's auc: 0.673546\tvalid_1's binary_logloss: 0.214807\n",
      "[157]\ttraining's auc: 0.70568\ttraining's binary_logloss: 0.215789\tvalid_1's auc: 0.673681\tvalid_1's binary_logloss: 0.21478\n",
      "[158]\ttraining's auc: 0.705937\ttraining's binary_logloss: 0.215743\tvalid_1's auc: 0.673756\tvalid_1's binary_logloss: 0.214753\n",
      "[159]\ttraining's auc: 0.706145\ttraining's binary_logloss: 0.215703\tvalid_1's auc: 0.673755\tvalid_1's binary_logloss: 0.214741\n",
      "[160]\ttraining's auc: 0.70637\ttraining's binary_logloss: 0.215664\tvalid_1's auc: 0.673821\tvalid_1's binary_logloss: 0.214724\n",
      "[161]\ttraining's auc: 0.706845\ttraining's binary_logloss: 0.215597\tvalid_1's auc: 0.674168\tvalid_1's binary_logloss: 0.214677\n",
      "[162]\ttraining's auc: 0.707086\ttraining's binary_logloss: 0.215553\tvalid_1's auc: 0.674321\tvalid_1's binary_logloss: 0.214652\n",
      "[163]\ttraining's auc: 0.707364\ttraining's binary_logloss: 0.215515\tvalid_1's auc: 0.674391\tvalid_1's binary_logloss: 0.21464\n",
      "[164]\ttraining's auc: 0.707599\ttraining's binary_logloss: 0.215477\tvalid_1's auc: 0.674427\tvalid_1's binary_logloss: 0.214627\n",
      "[165]\ttraining's auc: 0.707784\ttraining's binary_logloss: 0.215432\tvalid_1's auc: 0.674554\tvalid_1's binary_logloss: 0.214602\n",
      "[166]\ttraining's auc: 0.707968\ttraining's binary_logloss: 0.215389\tvalid_1's auc: 0.674561\tvalid_1's binary_logloss: 0.214586\n",
      "[167]\ttraining's auc: 0.708242\ttraining's binary_logloss: 0.215349\tvalid_1's auc: 0.674675\tvalid_1's binary_logloss: 0.214571\n",
      "[168]\ttraining's auc: 0.708497\ttraining's binary_logloss: 0.215309\tvalid_1's auc: 0.674778\tvalid_1's binary_logloss: 0.214554\n",
      "[169]\ttraining's auc: 0.708735\ttraining's binary_logloss: 0.215273\tvalid_1's auc: 0.674811\tvalid_1's binary_logloss: 0.214545\n",
      "[170]\ttraining's auc: 0.70893\ttraining's binary_logloss: 0.215237\tvalid_1's auc: 0.674769\tvalid_1's binary_logloss: 0.214539\n",
      "[171]\ttraining's auc: 0.709127\ttraining's binary_logloss: 0.215201\tvalid_1's auc: 0.674786\tvalid_1's binary_logloss: 0.214528\n",
      "[172]\ttraining's auc: 0.709389\ttraining's binary_logloss: 0.215163\tvalid_1's auc: 0.674925\tvalid_1's binary_logloss: 0.214506\n",
      "[173]\ttraining's auc: 0.70979\ttraining's binary_logloss: 0.215094\tvalid_1's auc: 0.675194\tvalid_1's binary_logloss: 0.214464\n",
      "[174]\ttraining's auc: 0.710007\ttraining's binary_logloss: 0.215055\tvalid_1's auc: 0.675241\tvalid_1's binary_logloss: 0.214451\n",
      "[175]\ttraining's auc: 0.710244\ttraining's binary_logloss: 0.215014\tvalid_1's auc: 0.675324\tvalid_1's binary_logloss: 0.214433\n",
      "[176]\ttraining's auc: 0.710499\ttraining's binary_logloss: 0.214974\tvalid_1's auc: 0.675425\tvalid_1's binary_logloss: 0.214414\n",
      "[177]\ttraining's auc: 0.710747\ttraining's binary_logloss: 0.214933\tvalid_1's auc: 0.675444\tvalid_1's binary_logloss: 0.214403\n",
      "[178]\ttraining's auc: 0.710992\ttraining's binary_logloss: 0.214892\tvalid_1's auc: 0.675484\tvalid_1's binary_logloss: 0.214389\n",
      "[179]\ttraining's auc: 0.711191\ttraining's binary_logloss: 0.214853\tvalid_1's auc: 0.675582\tvalid_1's binary_logloss: 0.214375\n",
      "[180]\ttraining's auc: 0.711378\ttraining's binary_logloss: 0.214821\tvalid_1's auc: 0.675609\tvalid_1's binary_logloss: 0.214368\n",
      "[181]\ttraining's auc: 0.71163\ttraining's binary_logloss: 0.214779\tvalid_1's auc: 0.675755\tvalid_1's binary_logloss: 0.214344\n",
      "[182]\ttraining's auc: 0.711931\ttraining's binary_logloss: 0.214731\tvalid_1's auc: 0.675988\tvalid_1's binary_logloss: 0.214316\n",
      "[183]\ttraining's auc: 0.712101\ttraining's binary_logloss: 0.214701\tvalid_1's auc: 0.676037\tvalid_1's binary_logloss: 0.214308\n",
      "[184]\ttraining's auc: 0.712272\ttraining's binary_logloss: 0.214667\tvalid_1's auc: 0.676065\tvalid_1's binary_logloss: 0.214298\n",
      "[185]\ttraining's auc: 0.712414\ttraining's binary_logloss: 0.214636\tvalid_1's auc: 0.67615\tvalid_1's binary_logloss: 0.214283\n",
      "[186]\ttraining's auc: 0.712663\ttraining's binary_logloss: 0.214595\tvalid_1's auc: 0.676245\tvalid_1's binary_logloss: 0.214265\n",
      "[187]\ttraining's auc: 0.712961\ttraining's binary_logloss: 0.214543\tvalid_1's auc: 0.67644\tvalid_1's binary_logloss: 0.214233\n",
      "[188]\ttraining's auc: 0.713167\ttraining's binary_logloss: 0.214505\tvalid_1's auc: 0.676597\tvalid_1's binary_logloss: 0.21421\n",
      "[189]\ttraining's auc: 0.713366\ttraining's binary_logloss: 0.214469\tvalid_1's auc: 0.676611\tvalid_1's binary_logloss: 0.214202\n",
      "[190]\ttraining's auc: 0.713577\ttraining's binary_logloss: 0.214431\tvalid_1's auc: 0.676704\tvalid_1's binary_logloss: 0.214182\n",
      "[191]\ttraining's auc: 0.713929\ttraining's binary_logloss: 0.214375\tvalid_1's auc: 0.676982\tvalid_1's binary_logloss: 0.214142\n",
      "[192]\ttraining's auc: 0.714217\ttraining's binary_logloss: 0.214321\tvalid_1's auc: 0.677204\tvalid_1's binary_logloss: 0.214111\n",
      "[193]\ttraining's auc: 0.71447\ttraining's binary_logloss: 0.214277\tvalid_1's auc: 0.677285\tvalid_1's binary_logloss: 0.214092\n",
      "[194]\ttraining's auc: 0.714613\ttraining's binary_logloss: 0.214245\tvalid_1's auc: 0.677252\tvalid_1's binary_logloss: 0.214088\n",
      "[195]\ttraining's auc: 0.714807\ttraining's binary_logloss: 0.214207\tvalid_1's auc: 0.677325\tvalid_1's binary_logloss: 0.214074\n",
      "[196]\ttraining's auc: 0.715015\ttraining's binary_logloss: 0.214173\tvalid_1's auc: 0.677266\tvalid_1's binary_logloss: 0.214073\n",
      "[197]\ttraining's auc: 0.715176\ttraining's binary_logloss: 0.214141\tvalid_1's auc: 0.677301\tvalid_1's binary_logloss: 0.214062\n",
      "[198]\ttraining's auc: 0.715311\ttraining's binary_logloss: 0.214107\tvalid_1's auc: 0.67734\tvalid_1's binary_logloss: 0.214051\n",
      "[199]\ttraining's auc: 0.715484\ttraining's binary_logloss: 0.214071\tvalid_1's auc: 0.677422\tvalid_1's binary_logloss: 0.214037\n",
      "[200]\ttraining's auc: 0.715669\ttraining's binary_logloss: 0.214043\tvalid_1's auc: 0.677406\tvalid_1's binary_logloss: 0.214031\n",
      "[201]\ttraining's auc: 0.715847\ttraining's binary_logloss: 0.214008\tvalid_1's auc: 0.677399\tvalid_1's binary_logloss: 0.214019\n",
      "[202]\ttraining's auc: 0.716026\ttraining's binary_logloss: 0.213977\tvalid_1's auc: 0.677414\tvalid_1's binary_logloss: 0.214014\n",
      "[203]\ttraining's auc: 0.716299\ttraining's binary_logloss: 0.213939\tvalid_1's auc: 0.677402\tvalid_1's binary_logloss: 0.214011\n",
      "[204]\ttraining's auc: 0.716512\ttraining's binary_logloss: 0.213902\tvalid_1's auc: 0.67745\tvalid_1's binary_logloss: 0.213995\n",
      "[205]\ttraining's auc: 0.716875\ttraining's binary_logloss: 0.213846\tvalid_1's auc: 0.677682\tvalid_1's binary_logloss: 0.213964\n",
      "[206]\ttraining's auc: 0.717122\ttraining's binary_logloss: 0.213809\tvalid_1's auc: 0.677768\tvalid_1's binary_logloss: 0.213947\n",
      "[207]\ttraining's auc: 0.717323\ttraining's binary_logloss: 0.213776\tvalid_1's auc: 0.677808\tvalid_1's binary_logloss: 0.213939\n",
      "[208]\ttraining's auc: 0.717471\ttraining's binary_logloss: 0.213746\tvalid_1's auc: 0.677848\tvalid_1's binary_logloss: 0.213931\n",
      "[209]\ttraining's auc: 0.717666\ttraining's binary_logloss: 0.213708\tvalid_1's auc: 0.677955\tvalid_1's binary_logloss: 0.213911\n",
      "[210]\ttraining's auc: 0.717841\ttraining's binary_logloss: 0.213674\tvalid_1's auc: 0.67798\tvalid_1's binary_logloss: 0.213903\n",
      "[211]\ttraining's auc: 0.718024\ttraining's binary_logloss: 0.213638\tvalid_1's auc: 0.677984\tvalid_1's binary_logloss: 0.213898\n",
      "[212]\ttraining's auc: 0.718172\ttraining's binary_logloss: 0.213603\tvalid_1's auc: 0.67798\tvalid_1's binary_logloss: 0.213891\n",
      "[213]\ttraining's auc: 0.718371\ttraining's binary_logloss: 0.213572\tvalid_1's auc: 0.678072\tvalid_1's binary_logloss: 0.213877\n",
      "[214]\ttraining's auc: 0.718531\ttraining's binary_logloss: 0.213541\tvalid_1's auc: 0.678087\tvalid_1's binary_logloss: 0.213868\n",
      "[215]\ttraining's auc: 0.718751\ttraining's binary_logloss: 0.213506\tvalid_1's auc: 0.678183\tvalid_1's binary_logloss: 0.213856\n",
      "[216]\ttraining's auc: 0.71896\ttraining's binary_logloss: 0.213472\tvalid_1's auc: 0.678245\tvalid_1's binary_logloss: 0.213845\n",
      "[217]\ttraining's auc: 0.719156\ttraining's binary_logloss: 0.213441\tvalid_1's auc: 0.678195\tvalid_1's binary_logloss: 0.213849\n",
      "[218]\ttraining's auc: 0.719349\ttraining's binary_logloss: 0.213412\tvalid_1's auc: 0.678196\tvalid_1's binary_logloss: 0.213846\n",
      "[219]\ttraining's auc: 0.719549\ttraining's binary_logloss: 0.21338\tvalid_1's auc: 0.678199\tvalid_1's binary_logloss: 0.213839\n",
      "[220]\ttraining's auc: 0.719656\ttraining's binary_logloss: 0.213349\tvalid_1's auc: 0.678161\tvalid_1's binary_logloss: 0.213839\n",
      "[221]\ttraining's auc: 0.719842\ttraining's binary_logloss: 0.213315\tvalid_1's auc: 0.678199\tvalid_1's binary_logloss: 0.213825\n",
      "[222]\ttraining's auc: 0.72003\ttraining's binary_logloss: 0.213284\tvalid_1's auc: 0.678165\tvalid_1's binary_logloss: 0.21382\n",
      "[223]\ttraining's auc: 0.720203\ttraining's binary_logloss: 0.213258\tvalid_1's auc: 0.678196\tvalid_1's binary_logloss: 0.213817\n",
      "[224]\ttraining's auc: 0.720365\ttraining's binary_logloss: 0.21323\tvalid_1's auc: 0.678209\tvalid_1's binary_logloss: 0.21381\n",
      "[225]\ttraining's auc: 0.720568\ttraining's binary_logloss: 0.213198\tvalid_1's auc: 0.678233\tvalid_1's binary_logloss: 0.213805\n",
      "[226]\ttraining's auc: 0.720716\ttraining's binary_logloss: 0.213166\tvalid_1's auc: 0.678179\tvalid_1's binary_logloss: 0.213801\n",
      "[227]\ttraining's auc: 0.72085\ttraining's binary_logloss: 0.213136\tvalid_1's auc: 0.678142\tvalid_1's binary_logloss: 0.213803\n",
      "[228]\ttraining's auc: 0.721026\ttraining's binary_logloss: 0.213101\tvalid_1's auc: 0.678231\tvalid_1's binary_logloss: 0.213789\n",
      "[229]\ttraining's auc: 0.721206\ttraining's binary_logloss: 0.21307\tvalid_1's auc: 0.678282\tvalid_1's binary_logloss: 0.213782\n",
      "[230]\ttraining's auc: 0.721395\ttraining's binary_logloss: 0.213037\tvalid_1's auc: 0.678316\tvalid_1's binary_logloss: 0.213772\n",
      "[231]\ttraining's auc: 0.721568\ttraining's binary_logloss: 0.213006\tvalid_1's auc: 0.678319\tvalid_1's binary_logloss: 0.213765\n",
      "[232]\ttraining's auc: 0.721823\ttraining's binary_logloss: 0.212964\tvalid_1's auc: 0.678518\tvalid_1's binary_logloss: 0.213737\n",
      "[233]\ttraining's auc: 0.722058\ttraining's binary_logloss: 0.212929\tvalid_1's auc: 0.678532\tvalid_1's binary_logloss: 0.213732\n",
      "[234]\ttraining's auc: 0.722244\ttraining's binary_logloss: 0.212894\tvalid_1's auc: 0.678558\tvalid_1's binary_logloss: 0.213726\n",
      "[235]\ttraining's auc: 0.722382\ttraining's binary_logloss: 0.212864\tvalid_1's auc: 0.678537\tvalid_1's binary_logloss: 0.213724\n",
      "[236]\ttraining's auc: 0.722507\ttraining's binary_logloss: 0.212833\tvalid_1's auc: 0.67855\tvalid_1's binary_logloss: 0.213719\n",
      "[237]\ttraining's auc: 0.722734\ttraining's binary_logloss: 0.21279\tvalid_1's auc: 0.678689\tvalid_1's binary_logloss: 0.213699\n",
      "[238]\ttraining's auc: 0.722983\ttraining's binary_logloss: 0.21275\tvalid_1's auc: 0.678812\tvalid_1's binary_logloss: 0.21368\n",
      "[239]\ttraining's auc: 0.723143\ttraining's binary_logloss: 0.21272\tvalid_1's auc: 0.67887\tvalid_1's binary_logloss: 0.21367\n",
      "[240]\ttraining's auc: 0.723289\ttraining's binary_logloss: 0.21269\tvalid_1's auc: 0.678884\tvalid_1's binary_logloss: 0.213664\n",
      "[241]\ttraining's auc: 0.72341\ttraining's binary_logloss: 0.21266\tvalid_1's auc: 0.678926\tvalid_1's binary_logloss: 0.213651\n",
      "[242]\ttraining's auc: 0.723622\ttraining's binary_logloss: 0.212627\tvalid_1's auc: 0.678959\tvalid_1's binary_logloss: 0.213643\n",
      "[243]\ttraining's auc: 0.723841\ttraining's binary_logloss: 0.212595\tvalid_1's auc: 0.678988\tvalid_1's binary_logloss: 0.213637\n",
      "[244]\ttraining's auc: 0.72408\ttraining's binary_logloss: 0.212559\tvalid_1's auc: 0.679066\tvalid_1's binary_logloss: 0.213625\n",
      "[245]\ttraining's auc: 0.724368\ttraining's binary_logloss: 0.212509\tvalid_1's auc: 0.679213\tvalid_1's binary_logloss: 0.213601\n",
      "[246]\ttraining's auc: 0.724554\ttraining's binary_logloss: 0.212474\tvalid_1's auc: 0.679243\tvalid_1's binary_logloss: 0.213592\n",
      "[247]\ttraining's auc: 0.724722\ttraining's binary_logloss: 0.21244\tvalid_1's auc: 0.679292\tvalid_1's binary_logloss: 0.213581\n",
      "[248]\ttraining's auc: 0.724845\ttraining's binary_logloss: 0.212409\tvalid_1's auc: 0.679424\tvalid_1's binary_logloss: 0.213564\n",
      "[249]\ttraining's auc: 0.725047\ttraining's binary_logloss: 0.212378\tvalid_1's auc: 0.679457\tvalid_1's binary_logloss: 0.213558\n",
      "[250]\ttraining's auc: 0.725266\ttraining's binary_logloss: 0.212345\tvalid_1's auc: 0.679445\tvalid_1's binary_logloss: 0.213553\n",
      "[251]\ttraining's auc: 0.725433\ttraining's binary_logloss: 0.212313\tvalid_1's auc: 0.679514\tvalid_1's binary_logloss: 0.213546\n",
      "[252]\ttraining's auc: 0.725563\ttraining's binary_logloss: 0.212285\tvalid_1's auc: 0.679518\tvalid_1's binary_logloss: 0.21354\n",
      "[253]\ttraining's auc: 0.725761\ttraining's binary_logloss: 0.212251\tvalid_1's auc: 0.679538\tvalid_1's binary_logloss: 0.213535\n",
      "[254]\ttraining's auc: 0.726\ttraining's binary_logloss: 0.212211\tvalid_1's auc: 0.679753\tvalid_1's binary_logloss: 0.213507\n",
      "[255]\ttraining's auc: 0.726154\ttraining's binary_logloss: 0.212179\tvalid_1's auc: 0.67985\tvalid_1's binary_logloss: 0.213488\n",
      "[256]\ttraining's auc: 0.726317\ttraining's binary_logloss: 0.212154\tvalid_1's auc: 0.679905\tvalid_1's binary_logloss: 0.21348\n",
      "[257]\ttraining's auc: 0.72642\ttraining's binary_logloss: 0.212131\tvalid_1's auc: 0.679927\tvalid_1's binary_logloss: 0.213472\n",
      "[258]\ttraining's auc: 0.726491\ttraining's binary_logloss: 0.212115\tvalid_1's auc: 0.679898\tvalid_1's binary_logloss: 0.213471\n",
      "[259]\ttraining's auc: 0.726713\ttraining's binary_logloss: 0.212079\tvalid_1's auc: 0.679966\tvalid_1's binary_logloss: 0.213465\n",
      "[260]\ttraining's auc: 0.726869\ttraining's binary_logloss: 0.212047\tvalid_1's auc: 0.680004\tvalid_1's binary_logloss: 0.213459\n",
      "[261]\ttraining's auc: 0.727127\ttraining's binary_logloss: 0.212012\tvalid_1's auc: 0.680057\tvalid_1's binary_logloss: 0.213448\n",
      "[262]\ttraining's auc: 0.727323\ttraining's binary_logloss: 0.211984\tvalid_1's auc: 0.6801\tvalid_1's binary_logloss: 0.213441\n",
      "[263]\ttraining's auc: 0.727494\ttraining's binary_logloss: 0.211952\tvalid_1's auc: 0.680183\tvalid_1's binary_logloss: 0.213426\n",
      "[264]\ttraining's auc: 0.72764\ttraining's binary_logloss: 0.211919\tvalid_1's auc: 0.680282\tvalid_1's binary_logloss: 0.213407\n",
      "[265]\ttraining's auc: 0.727776\ttraining's binary_logloss: 0.211891\tvalid_1's auc: 0.680297\tvalid_1's binary_logloss: 0.213402\n",
      "[266]\ttraining's auc: 0.728059\ttraining's binary_logloss: 0.211851\tvalid_1's auc: 0.680471\tvalid_1's binary_logloss: 0.213382\n",
      "[267]\ttraining's auc: 0.728325\ttraining's binary_logloss: 0.211808\tvalid_1's auc: 0.680603\tvalid_1's binary_logloss: 0.213364\n",
      "[268]\ttraining's auc: 0.728568\ttraining's binary_logloss: 0.211776\tvalid_1's auc: 0.680704\tvalid_1's binary_logloss: 0.213354\n",
      "[269]\ttraining's auc: 0.728702\ttraining's binary_logloss: 0.21175\tvalid_1's auc: 0.680752\tvalid_1's binary_logloss: 0.213342\n",
      "[270]\ttraining's auc: 0.728852\ttraining's binary_logloss: 0.211722\tvalid_1's auc: 0.680772\tvalid_1's binary_logloss: 0.213339\n",
      "[271]\ttraining's auc: 0.728975\ttraining's binary_logloss: 0.211695\tvalid_1's auc: 0.680796\tvalid_1's binary_logloss: 0.213334\n",
      "[272]\ttraining's auc: 0.729139\ttraining's binary_logloss: 0.211665\tvalid_1's auc: 0.680849\tvalid_1's binary_logloss: 0.213324\n",
      "[273]\ttraining's auc: 0.729266\ttraining's binary_logloss: 0.211637\tvalid_1's auc: 0.680826\tvalid_1's binary_logloss: 0.21332\n",
      "[274]\ttraining's auc: 0.729404\ttraining's binary_logloss: 0.211609\tvalid_1's auc: 0.680793\tvalid_1's binary_logloss: 0.21332\n",
      "[275]\ttraining's auc: 0.729569\ttraining's binary_logloss: 0.211577\tvalid_1's auc: 0.680853\tvalid_1's binary_logloss: 0.213308\n",
      "[276]\ttraining's auc: 0.729753\ttraining's binary_logloss: 0.211547\tvalid_1's auc: 0.68096\tvalid_1's binary_logloss: 0.213294\n",
      "[277]\ttraining's auc: 0.729839\ttraining's binary_logloss: 0.21153\tvalid_1's auc: 0.680923\tvalid_1's binary_logloss: 0.213295\n",
      "[278]\ttraining's auc: 0.729918\ttraining's binary_logloss: 0.211513\tvalid_1's auc: 0.680918\tvalid_1's binary_logloss: 0.213292\n",
      "[279]\ttraining's auc: 0.730107\ttraining's binary_logloss: 0.211482\tvalid_1's auc: 0.680969\tvalid_1's binary_logloss: 0.213284\n",
      "[280]\ttraining's auc: 0.73028\ttraining's binary_logloss: 0.21145\tvalid_1's auc: 0.680981\tvalid_1's binary_logloss: 0.21328\n",
      "[281]\ttraining's auc: 0.730426\ttraining's binary_logloss: 0.21142\tvalid_1's auc: 0.680986\tvalid_1's binary_logloss: 0.213275\n",
      "[282]\ttraining's auc: 0.730586\ttraining's binary_logloss: 0.21139\tvalid_1's auc: 0.681044\tvalid_1's binary_logloss: 0.213268\n",
      "[283]\ttraining's auc: 0.730799\ttraining's binary_logloss: 0.211354\tvalid_1's auc: 0.681153\tvalid_1's binary_logloss: 0.213251\n",
      "[284]\ttraining's auc: 0.731078\ttraining's binary_logloss: 0.211313\tvalid_1's auc: 0.681273\tvalid_1's binary_logloss: 0.213237\n",
      "[285]\ttraining's auc: 0.731178\ttraining's binary_logloss: 0.211283\tvalid_1's auc: 0.681346\tvalid_1's binary_logloss: 0.213228\n",
      "[286]\ttraining's auc: 0.731292\ttraining's binary_logloss: 0.211253\tvalid_1's auc: 0.681375\tvalid_1's binary_logloss: 0.213221\n",
      "[287]\ttraining's auc: 0.731476\ttraining's binary_logloss: 0.211224\tvalid_1's auc: 0.681369\tvalid_1's binary_logloss: 0.21322\n",
      "[288]\ttraining's auc: 0.731624\ttraining's binary_logloss: 0.211195\tvalid_1's auc: 0.681433\tvalid_1's binary_logloss: 0.213209\n",
      "[289]\ttraining's auc: 0.731749\ttraining's binary_logloss: 0.211172\tvalid_1's auc: 0.681416\tvalid_1's binary_logloss: 0.213207\n",
      "[290]\ttraining's auc: 0.73191\ttraining's binary_logloss: 0.211145\tvalid_1's auc: 0.681469\tvalid_1's binary_logloss: 0.213198\n",
      "[291]\ttraining's auc: 0.732064\ttraining's binary_logloss: 0.211117\tvalid_1's auc: 0.681423\tvalid_1's binary_logloss: 0.213203\n",
      "[292]\ttraining's auc: 0.732152\ttraining's binary_logloss: 0.211099\tvalid_1's auc: 0.681393\tvalid_1's binary_logloss: 0.213203\n",
      "[293]\ttraining's auc: 0.73229\ttraining's binary_logloss: 0.211077\tvalid_1's auc: 0.681415\tvalid_1's binary_logloss: 0.2132\n",
      "[294]\ttraining's auc: 0.732421\ttraining's binary_logloss: 0.211049\tvalid_1's auc: 0.681456\tvalid_1's binary_logloss: 0.213193\n",
      "[295]\ttraining's auc: 0.732639\ttraining's binary_logloss: 0.211019\tvalid_1's auc: 0.681426\tvalid_1's binary_logloss: 0.213193\n",
      "[296]\ttraining's auc: 0.732826\ttraining's binary_logloss: 0.210989\tvalid_1's auc: 0.681475\tvalid_1's binary_logloss: 0.213186\n",
      "[297]\ttraining's auc: 0.732987\ttraining's binary_logloss: 0.210964\tvalid_1's auc: 0.681446\tvalid_1's binary_logloss: 0.213187\n",
      "[298]\ttraining's auc: 0.733117\ttraining's binary_logloss: 0.210937\tvalid_1's auc: 0.681433\tvalid_1's binary_logloss: 0.213185\n",
      "[299]\ttraining's auc: 0.733321\ttraining's binary_logloss: 0.210906\tvalid_1's auc: 0.681452\tvalid_1's binary_logloss: 0.213179\n",
      "[300]\ttraining's auc: 0.733468\ttraining's binary_logloss: 0.210878\tvalid_1's auc: 0.681467\tvalid_1's binary_logloss: 0.213175\n",
      "[301]\ttraining's auc: 0.733676\ttraining's binary_logloss: 0.210844\tvalid_1's auc: 0.681624\tvalid_1's binary_logloss: 0.213156\n",
      "[302]\ttraining's auc: 0.733874\ttraining's binary_logloss: 0.210807\tvalid_1's auc: 0.681787\tvalid_1's binary_logloss: 0.213136\n",
      "[303]\ttraining's auc: 0.734048\ttraining's binary_logloss: 0.210769\tvalid_1's auc: 0.681922\tvalid_1's binary_logloss: 0.213121\n",
      "[304]\ttraining's auc: 0.734259\ttraining's binary_logloss: 0.210736\tvalid_1's auc: 0.682022\tvalid_1's binary_logloss: 0.213107\n",
      "[305]\ttraining's auc: 0.734453\ttraining's binary_logloss: 0.210701\tvalid_1's auc: 0.68206\tvalid_1's binary_logloss: 0.213099\n",
      "[306]\ttraining's auc: 0.73462\ttraining's binary_logloss: 0.21067\tvalid_1's auc: 0.682079\tvalid_1's binary_logloss: 0.213097\n",
      "[307]\ttraining's auc: 0.734796\ttraining's binary_logloss: 0.210641\tvalid_1's auc: 0.682061\tvalid_1's binary_logloss: 0.213096\n",
      "[308]\ttraining's auc: 0.734944\ttraining's binary_logloss: 0.210616\tvalid_1's auc: 0.682019\tvalid_1's binary_logloss: 0.2131\n",
      "[309]\ttraining's auc: 0.735173\ttraining's binary_logloss: 0.210577\tvalid_1's auc: 0.682148\tvalid_1's binary_logloss: 0.213084\n",
      "[310]\ttraining's auc: 0.735419\ttraining's binary_logloss: 0.210545\tvalid_1's auc: 0.682208\tvalid_1's binary_logloss: 0.213077\n",
      "[311]\ttraining's auc: 0.73559\ttraining's binary_logloss: 0.210517\tvalid_1's auc: 0.682226\tvalid_1's binary_logloss: 0.213073\n",
      "[312]\ttraining's auc: 0.735737\ttraining's binary_logloss: 0.210493\tvalid_1's auc: 0.682237\tvalid_1's binary_logloss: 0.21307\n",
      "[313]\ttraining's auc: 0.735885\ttraining's binary_logloss: 0.210464\tvalid_1's auc: 0.682268\tvalid_1's binary_logloss: 0.213061\n",
      "[314]\ttraining's auc: 0.735984\ttraining's binary_logloss: 0.210446\tvalid_1's auc: 0.682289\tvalid_1's binary_logloss: 0.213057\n",
      "[315]\ttraining's auc: 0.736141\ttraining's binary_logloss: 0.210419\tvalid_1's auc: 0.682324\tvalid_1's binary_logloss: 0.213048\n",
      "[316]\ttraining's auc: 0.736326\ttraining's binary_logloss: 0.210389\tvalid_1's auc: 0.682319\tvalid_1's binary_logloss: 0.213044\n",
      "[317]\ttraining's auc: 0.736526\ttraining's binary_logloss: 0.210359\tvalid_1's auc: 0.682426\tvalid_1's binary_logloss: 0.213032\n",
      "[318]\ttraining's auc: 0.736726\ttraining's binary_logloss: 0.210331\tvalid_1's auc: 0.682463\tvalid_1's binary_logloss: 0.213024\n",
      "[319]\ttraining's auc: 0.7368\ttraining's binary_logloss: 0.210313\tvalid_1's auc: 0.6825\tvalid_1's binary_logloss: 0.213018\n",
      "[320]\ttraining's auc: 0.736939\ttraining's binary_logloss: 0.210284\tvalid_1's auc: 0.682571\tvalid_1's binary_logloss: 0.213008\n",
      "[321]\ttraining's auc: 0.737075\ttraining's binary_logloss: 0.210253\tvalid_1's auc: 0.682597\tvalid_1's binary_logloss: 0.213\n",
      "[322]\ttraining's auc: 0.737234\ttraining's binary_logloss: 0.210225\tvalid_1's auc: 0.682629\tvalid_1's binary_logloss: 0.212991\n",
      "[323]\ttraining's auc: 0.737414\ttraining's binary_logloss: 0.210199\tvalid_1's auc: 0.682714\tvalid_1's binary_logloss: 0.212982\n",
      "[324]\ttraining's auc: 0.737553\ttraining's binary_logloss: 0.210175\tvalid_1's auc: 0.682737\tvalid_1's binary_logloss: 0.21298\n",
      "[325]\ttraining's auc: 0.73774\ttraining's binary_logloss: 0.210148\tvalid_1's auc: 0.682729\tvalid_1's binary_logloss: 0.212977\n",
      "[326]\ttraining's auc: 0.737924\ttraining's binary_logloss: 0.210123\tvalid_1's auc: 0.682767\tvalid_1's binary_logloss: 0.212973\n",
      "[327]\ttraining's auc: 0.738061\ttraining's binary_logloss: 0.210097\tvalid_1's auc: 0.682787\tvalid_1's binary_logloss: 0.212969\n",
      "[328]\ttraining's auc: 0.738191\ttraining's binary_logloss: 0.21007\tvalid_1's auc: 0.6828\tvalid_1's binary_logloss: 0.212966\n",
      "[329]\ttraining's auc: 0.738324\ttraining's binary_logloss: 0.210044\tvalid_1's auc: 0.682807\tvalid_1's binary_logloss: 0.212964\n",
      "[330]\ttraining's auc: 0.738455\ttraining's binary_logloss: 0.21002\tvalid_1's auc: 0.682832\tvalid_1's binary_logloss: 0.212961\n",
      "[331]\ttraining's auc: 0.738596\ttraining's binary_logloss: 0.209994\tvalid_1's auc: 0.682847\tvalid_1's binary_logloss: 0.212953\n",
      "[332]\ttraining's auc: 0.738793\ttraining's binary_logloss: 0.209962\tvalid_1's auc: 0.682901\tvalid_1's binary_logloss: 0.212943\n",
      "[333]\ttraining's auc: 0.738892\ttraining's binary_logloss: 0.209944\tvalid_1's auc: 0.682925\tvalid_1's binary_logloss: 0.212941\n",
      "[334]\ttraining's auc: 0.738968\ttraining's binary_logloss: 0.209931\tvalid_1's auc: 0.6829\tvalid_1's binary_logloss: 0.212943\n",
      "[335]\ttraining's auc: 0.739132\ttraining's binary_logloss: 0.209905\tvalid_1's auc: 0.682893\tvalid_1's binary_logloss: 0.212938\n",
      "[336]\ttraining's auc: 0.739334\ttraining's binary_logloss: 0.209876\tvalid_1's auc: 0.682892\tvalid_1's binary_logloss: 0.212936\n",
      "[337]\ttraining's auc: 0.739522\ttraining's binary_logloss: 0.209846\tvalid_1's auc: 0.682904\tvalid_1's binary_logloss: 0.212935\n",
      "[338]\ttraining's auc: 0.73969\ttraining's binary_logloss: 0.209817\tvalid_1's auc: 0.682916\tvalid_1's binary_logloss: 0.212932\n",
      "[339]\ttraining's auc: 0.739825\ttraining's binary_logloss: 0.209794\tvalid_1's auc: 0.682907\tvalid_1's binary_logloss: 0.212931\n",
      "[340]\ttraining's auc: 0.739982\ttraining's binary_logloss: 0.209767\tvalid_1's auc: 0.682911\tvalid_1's binary_logloss: 0.212927\n",
      "[341]\ttraining's auc: 0.74013\ttraining's binary_logloss: 0.209741\tvalid_1's auc: 0.682911\tvalid_1's binary_logloss: 0.212926\n",
      "[342]\ttraining's auc: 0.740323\ttraining's binary_logloss: 0.209713\tvalid_1's auc: 0.682987\tvalid_1's binary_logloss: 0.212918\n",
      "[343]\ttraining's auc: 0.740462\ttraining's binary_logloss: 0.209689\tvalid_1's auc: 0.682969\tvalid_1's binary_logloss: 0.21292\n",
      "[344]\ttraining's auc: 0.74057\ttraining's binary_logloss: 0.209659\tvalid_1's auc: 0.683015\tvalid_1's binary_logloss: 0.212912\n",
      "[345]\ttraining's auc: 0.740708\ttraining's binary_logloss: 0.209628\tvalid_1's auc: 0.683067\tvalid_1's binary_logloss: 0.212902\n",
      "[346]\ttraining's auc: 0.740857\ttraining's binary_logloss: 0.209599\tvalid_1's auc: 0.683088\tvalid_1's binary_logloss: 0.212896\n",
      "[347]\ttraining's auc: 0.741037\ttraining's binary_logloss: 0.209566\tvalid_1's auc: 0.683186\tvalid_1's binary_logloss: 0.212884\n",
      "[348]\ttraining's auc: 0.741174\ttraining's binary_logloss: 0.209533\tvalid_1's auc: 0.683249\tvalid_1's binary_logloss: 0.212871\n",
      "[349]\ttraining's auc: 0.741301\ttraining's binary_logloss: 0.209516\tvalid_1's auc: 0.683273\tvalid_1's binary_logloss: 0.212867\n",
      "[350]\ttraining's auc: 0.741427\ttraining's binary_logloss: 0.209494\tvalid_1's auc: 0.683346\tvalid_1's binary_logloss: 0.212861\n",
      "[351]\ttraining's auc: 0.741581\ttraining's binary_logloss: 0.20947\tvalid_1's auc: 0.683289\tvalid_1's binary_logloss: 0.212864\n",
      "[352]\ttraining's auc: 0.741718\ttraining's binary_logloss: 0.209444\tvalid_1's auc: 0.683246\tvalid_1's binary_logloss: 0.212866\n",
      "[353]\ttraining's auc: 0.741861\ttraining's binary_logloss: 0.209421\tvalid_1's auc: 0.683253\tvalid_1's binary_logloss: 0.212865\n",
      "[354]\ttraining's auc: 0.742011\ttraining's binary_logloss: 0.209396\tvalid_1's auc: 0.683282\tvalid_1's binary_logloss: 0.212857\n",
      "[355]\ttraining's auc: 0.742122\ttraining's binary_logloss: 0.209371\tvalid_1's auc: 0.683345\tvalid_1's binary_logloss: 0.212848\n",
      "[356]\ttraining's auc: 0.742265\ttraining's binary_logloss: 0.209344\tvalid_1's auc: 0.683372\tvalid_1's binary_logloss: 0.212842\n",
      "[357]\ttraining's auc: 0.742353\ttraining's binary_logloss: 0.209328\tvalid_1's auc: 0.683425\tvalid_1's binary_logloss: 0.212837\n",
      "[358]\ttraining's auc: 0.742442\ttraining's binary_logloss: 0.209313\tvalid_1's auc: 0.68347\tvalid_1's binary_logloss: 0.212834\n",
      "[359]\ttraining's auc: 0.742598\ttraining's binary_logloss: 0.209287\tvalid_1's auc: 0.683498\tvalid_1's binary_logloss: 0.21283\n",
      "[360]\ttraining's auc: 0.742738\ttraining's binary_logloss: 0.20926\tvalid_1's auc: 0.683546\tvalid_1's binary_logloss: 0.212823\n",
      "[361]\ttraining's auc: 0.742906\ttraining's binary_logloss: 0.209235\tvalid_1's auc: 0.68354\tvalid_1's binary_logloss: 0.212822\n",
      "[362]\ttraining's auc: 0.743054\ttraining's binary_logloss: 0.209213\tvalid_1's auc: 0.683528\tvalid_1's binary_logloss: 0.212824\n",
      "[363]\ttraining's auc: 0.743211\ttraining's binary_logloss: 0.209186\tvalid_1's auc: 0.683475\tvalid_1's binary_logloss: 0.212829\n",
      "[364]\ttraining's auc: 0.743379\ttraining's binary_logloss: 0.209159\tvalid_1's auc: 0.683457\tvalid_1's binary_logloss: 0.212829\n",
      "[365]\ttraining's auc: 0.743569\ttraining's binary_logloss: 0.209129\tvalid_1's auc: 0.683545\tvalid_1's binary_logloss: 0.212817\n",
      "[366]\ttraining's auc: 0.743711\ttraining's binary_logloss: 0.209105\tvalid_1's auc: 0.683499\tvalid_1's binary_logloss: 0.212821\n",
      "[367]\ttraining's auc: 0.7438\ttraining's binary_logloss: 0.209086\tvalid_1's auc: 0.683511\tvalid_1's binary_logloss: 0.212815\n",
      "[368]\ttraining's auc: 0.743962\ttraining's binary_logloss: 0.209056\tvalid_1's auc: 0.683529\tvalid_1's binary_logloss: 0.21281\n",
      "[369]\ttraining's auc: 0.744152\ttraining's binary_logloss: 0.209025\tvalid_1's auc: 0.683627\tvalid_1's binary_logloss: 0.212795\n",
      "[370]\ttraining's auc: 0.744248\ttraining's binary_logloss: 0.209005\tvalid_1's auc: 0.683631\tvalid_1's binary_logloss: 0.212796\n",
      "[371]\ttraining's auc: 0.744441\ttraining's binary_logloss: 0.208972\tvalid_1's auc: 0.683764\tvalid_1's binary_logloss: 0.21278\n",
      "[372]\ttraining's auc: 0.744578\ttraining's binary_logloss: 0.208942\tvalid_1's auc: 0.683841\tvalid_1's binary_logloss: 0.212771\n",
      "[373]\ttraining's auc: 0.744627\ttraining's binary_logloss: 0.208928\tvalid_1's auc: 0.683825\tvalid_1's binary_logloss: 0.212771\n",
      "[374]\ttraining's auc: 0.744701\ttraining's binary_logloss: 0.208912\tvalid_1's auc: 0.683815\tvalid_1's binary_logloss: 0.212771\n",
      "[375]\ttraining's auc: 0.744829\ttraining's binary_logloss: 0.208887\tvalid_1's auc: 0.683833\tvalid_1's binary_logloss: 0.212766\n",
      "[376]\ttraining's auc: 0.744991\ttraining's binary_logloss: 0.208858\tvalid_1's auc: 0.683901\tvalid_1's binary_logloss: 0.212756\n",
      "[377]\ttraining's auc: 0.745122\ttraining's binary_logloss: 0.208831\tvalid_1's auc: 0.683897\tvalid_1's binary_logloss: 0.212758\n",
      "[378]\ttraining's auc: 0.745242\ttraining's binary_logloss: 0.208806\tvalid_1's auc: 0.683874\tvalid_1's binary_logloss: 0.212759\n",
      "[379]\ttraining's auc: 0.745418\ttraining's binary_logloss: 0.20878\tvalid_1's auc: 0.683928\tvalid_1's binary_logloss: 0.212752\n",
      "[380]\ttraining's auc: 0.745616\ttraining's binary_logloss: 0.208748\tvalid_1's auc: 0.684001\tvalid_1's binary_logloss: 0.212744\n",
      "[381]\ttraining's auc: 0.745746\ttraining's binary_logloss: 0.208726\tvalid_1's auc: 0.684025\tvalid_1's binary_logloss: 0.21274\n",
      "[382]\ttraining's auc: 0.745822\ttraining's binary_logloss: 0.208705\tvalid_1's auc: 0.684027\tvalid_1's binary_logloss: 0.212739\n",
      "[383]\ttraining's auc: 0.745967\ttraining's binary_logloss: 0.208679\tvalid_1's auc: 0.684006\tvalid_1's binary_logloss: 0.212739\n",
      "[384]\ttraining's auc: 0.746104\ttraining's binary_logloss: 0.20865\tvalid_1's auc: 0.684017\tvalid_1's binary_logloss: 0.212733\n",
      "[385]\ttraining's auc: 0.746281\ttraining's binary_logloss: 0.208623\tvalid_1's auc: 0.683992\tvalid_1's binary_logloss: 0.212733\n",
      "[386]\ttraining's auc: 0.746451\ttraining's binary_logloss: 0.208587\tvalid_1's auc: 0.684061\tvalid_1's binary_logloss: 0.21272\n",
      "[387]\ttraining's auc: 0.746591\ttraining's binary_logloss: 0.208564\tvalid_1's auc: 0.684083\tvalid_1's binary_logloss: 0.212719\n",
      "[388]\ttraining's auc: 0.74675\ttraining's binary_logloss: 0.208533\tvalid_1's auc: 0.684176\tvalid_1's binary_logloss: 0.212707\n",
      "[389]\ttraining's auc: 0.74685\ttraining's binary_logloss: 0.208518\tvalid_1's auc: 0.684186\tvalid_1's binary_logloss: 0.212707\n",
      "[390]\ttraining's auc: 0.747012\ttraining's binary_logloss: 0.208491\tvalid_1's auc: 0.684185\tvalid_1's binary_logloss: 0.212707\n",
      "[391]\ttraining's auc: 0.747154\ttraining's binary_logloss: 0.208466\tvalid_1's auc: 0.68419\tvalid_1's binary_logloss: 0.212706\n",
      "[392]\ttraining's auc: 0.747264\ttraining's binary_logloss: 0.20844\tvalid_1's auc: 0.684264\tvalid_1's binary_logloss: 0.212695\n",
      "[393]\ttraining's auc: 0.747439\ttraining's binary_logloss: 0.208416\tvalid_1's auc: 0.684218\tvalid_1's binary_logloss: 0.212697\n",
      "[394]\ttraining's auc: 0.747599\ttraining's binary_logloss: 0.208392\tvalid_1's auc: 0.68419\tvalid_1's binary_logloss: 0.212698\n",
      "[395]\ttraining's auc: 0.74777\ttraining's binary_logloss: 0.208369\tvalid_1's auc: 0.684193\tvalid_1's binary_logloss: 0.212698\n",
      "[396]\ttraining's auc: 0.747913\ttraining's binary_logloss: 0.208344\tvalid_1's auc: 0.684213\tvalid_1's binary_logloss: 0.212695\n",
      "[397]\ttraining's auc: 0.74809\ttraining's binary_logloss: 0.208316\tvalid_1's auc: 0.684265\tvalid_1's binary_logloss: 0.212689\n",
      "[398]\ttraining's auc: 0.748281\ttraining's binary_logloss: 0.208285\tvalid_1's auc: 0.68434\tvalid_1's binary_logloss: 0.212682\n",
      "[399]\ttraining's auc: 0.7484\ttraining's binary_logloss: 0.208264\tvalid_1's auc: 0.68429\tvalid_1's binary_logloss: 0.212686\n",
      "[400]\ttraining's auc: 0.74857\ttraining's binary_logloss: 0.208235\tvalid_1's auc: 0.684364\tvalid_1's binary_logloss: 0.212676\n",
      "[401]\ttraining's auc: 0.74871\ttraining's binary_logloss: 0.20821\tvalid_1's auc: 0.684434\tvalid_1's binary_logloss: 0.212668\n",
      "[402]\ttraining's auc: 0.748871\ttraining's binary_logloss: 0.208184\tvalid_1's auc: 0.684487\tvalid_1's binary_logloss: 0.212661\n",
      "[403]\ttraining's auc: 0.748977\ttraining's binary_logloss: 0.208164\tvalid_1's auc: 0.68448\tvalid_1's binary_logloss: 0.212661\n",
      "[404]\ttraining's auc: 0.749078\ttraining's binary_logloss: 0.208142\tvalid_1's auc: 0.684476\tvalid_1's binary_logloss: 0.212659\n",
      "[405]\ttraining's auc: 0.7492\ttraining's binary_logloss: 0.208121\tvalid_1's auc: 0.684468\tvalid_1's binary_logloss: 0.21266\n",
      "[406]\ttraining's auc: 0.749303\ttraining's binary_logloss: 0.208099\tvalid_1's auc: 0.684465\tvalid_1's binary_logloss: 0.212661\n",
      "[407]\ttraining's auc: 0.749478\ttraining's binary_logloss: 0.208071\tvalid_1's auc: 0.684515\tvalid_1's binary_logloss: 0.212652\n",
      "[408]\ttraining's auc: 0.749642\ttraining's binary_logloss: 0.208045\tvalid_1's auc: 0.684563\tvalid_1's binary_logloss: 0.212647\n",
      "[409]\ttraining's auc: 0.749762\ttraining's binary_logloss: 0.208021\tvalid_1's auc: 0.684598\tvalid_1's binary_logloss: 0.21264\n",
      "[410]\ttraining's auc: 0.749911\ttraining's binary_logloss: 0.207994\tvalid_1's auc: 0.684606\tvalid_1's binary_logloss: 0.212637\n",
      "[411]\ttraining's auc: 0.750023\ttraining's binary_logloss: 0.207971\tvalid_1's auc: 0.684659\tvalid_1's binary_logloss: 0.212632\n",
      "[412]\ttraining's auc: 0.750127\ttraining's binary_logloss: 0.207952\tvalid_1's auc: 0.684657\tvalid_1's binary_logloss: 0.212631\n",
      "[413]\ttraining's auc: 0.750267\ttraining's binary_logloss: 0.207928\tvalid_1's auc: 0.684624\tvalid_1's binary_logloss: 0.212633\n",
      "[414]\ttraining's auc: 0.750461\ttraining's binary_logloss: 0.207895\tvalid_1's auc: 0.68477\tvalid_1's binary_logloss: 0.212617\n",
      "[415]\ttraining's auc: 0.750577\ttraining's binary_logloss: 0.207873\tvalid_1's auc: 0.684814\tvalid_1's binary_logloss: 0.212612\n",
      "[416]\ttraining's auc: 0.750692\ttraining's binary_logloss: 0.207852\tvalid_1's auc: 0.684815\tvalid_1's binary_logloss: 0.21261\n",
      "[417]\ttraining's auc: 0.75085\ttraining's binary_logloss: 0.207825\tvalid_1's auc: 0.684867\tvalid_1's binary_logloss: 0.212604\n",
      "[418]\ttraining's auc: 0.750995\ttraining's binary_logloss: 0.207801\tvalid_1's auc: 0.684857\tvalid_1's binary_logloss: 0.212609\n",
      "[419]\ttraining's auc: 0.751089\ttraining's binary_logloss: 0.207783\tvalid_1's auc: 0.684853\tvalid_1's binary_logloss: 0.21261\n",
      "[420]\ttraining's auc: 0.751197\ttraining's binary_logloss: 0.207763\tvalid_1's auc: 0.684795\tvalid_1's binary_logloss: 0.212617\n",
      "[421]\ttraining's auc: 0.751331\ttraining's binary_logloss: 0.207734\tvalid_1's auc: 0.684893\tvalid_1's binary_logloss: 0.212602\n",
      "[422]\ttraining's auc: 0.751495\ttraining's binary_logloss: 0.207708\tvalid_1's auc: 0.684946\tvalid_1's binary_logloss: 0.212594\n",
      "[423]\ttraining's auc: 0.751612\ttraining's binary_logloss: 0.207683\tvalid_1's auc: 0.684944\tvalid_1's binary_logloss: 0.212589\n",
      "[424]\ttraining's auc: 0.751719\ttraining's binary_logloss: 0.207661\tvalid_1's auc: 0.684916\tvalid_1's binary_logloss: 0.21259\n",
      "[425]\ttraining's auc: 0.751866\ttraining's binary_logloss: 0.207633\tvalid_1's auc: 0.684959\tvalid_1's binary_logloss: 0.212584\n",
      "[426]\ttraining's auc: 0.751981\ttraining's binary_logloss: 0.20761\tvalid_1's auc: 0.684932\tvalid_1's binary_logloss: 0.212587\n",
      "[427]\ttraining's auc: 0.752147\ttraining's binary_logloss: 0.207579\tvalid_1's auc: 0.685039\tvalid_1's binary_logloss: 0.212572\n",
      "[428]\ttraining's auc: 0.752202\ttraining's binary_logloss: 0.207567\tvalid_1's auc: 0.685033\tvalid_1's binary_logloss: 0.212573\n",
      "[429]\ttraining's auc: 0.752372\ttraining's binary_logloss: 0.207537\tvalid_1's auc: 0.685096\tvalid_1's binary_logloss: 0.212564\n",
      "[430]\ttraining's auc: 0.752513\ttraining's binary_logloss: 0.207509\tvalid_1's auc: 0.685175\tvalid_1's binary_logloss: 0.212553\n",
      "[431]\ttraining's auc: 0.752714\ttraining's binary_logloss: 0.207478\tvalid_1's auc: 0.685226\tvalid_1's binary_logloss: 0.212545\n",
      "[432]\ttraining's auc: 0.752884\ttraining's binary_logloss: 0.207448\tvalid_1's auc: 0.685271\tvalid_1's binary_logloss: 0.212537\n",
      "[433]\ttraining's auc: 0.753025\ttraining's binary_logloss: 0.207421\tvalid_1's auc: 0.685335\tvalid_1's binary_logloss: 0.212529\n",
      "[434]\ttraining's auc: 0.753222\ttraining's binary_logloss: 0.207393\tvalid_1's auc: 0.685366\tvalid_1's binary_logloss: 0.212526\n",
      "[435]\ttraining's auc: 0.753367\ttraining's binary_logloss: 0.207366\tvalid_1's auc: 0.685385\tvalid_1's binary_logloss: 0.212524\n",
      "[436]\ttraining's auc: 0.753531\ttraining's binary_logloss: 0.20734\tvalid_1's auc: 0.685425\tvalid_1's binary_logloss: 0.212518\n",
      "[437]\ttraining's auc: 0.75371\ttraining's binary_logloss: 0.207312\tvalid_1's auc: 0.6854\tvalid_1's binary_logloss: 0.212519\n",
      "[438]\ttraining's auc: 0.753802\ttraining's binary_logloss: 0.207292\tvalid_1's auc: 0.685385\tvalid_1's binary_logloss: 0.212518\n",
      "[439]\ttraining's auc: 0.753917\ttraining's binary_logloss: 0.20727\tvalid_1's auc: 0.685377\tvalid_1's binary_logloss: 0.212513\n",
      "[440]\ttraining's auc: 0.75404\ttraining's binary_logloss: 0.207248\tvalid_1's auc: 0.685364\tvalid_1's binary_logloss: 0.212509\n",
      "[441]\ttraining's auc: 0.754166\ttraining's binary_logloss: 0.207224\tvalid_1's auc: 0.685374\tvalid_1's binary_logloss: 0.212507\n",
      "[442]\ttraining's auc: 0.754295\ttraining's binary_logloss: 0.207198\tvalid_1's auc: 0.685317\tvalid_1's binary_logloss: 0.212513\n",
      "[443]\ttraining's auc: 0.754414\ttraining's binary_logloss: 0.207176\tvalid_1's auc: 0.685285\tvalid_1's binary_logloss: 0.212516\n",
      "[444]\ttraining's auc: 0.754515\ttraining's binary_logloss: 0.207154\tvalid_1's auc: 0.685278\tvalid_1's binary_logloss: 0.212516\n",
      "[445]\ttraining's auc: 0.754638\ttraining's binary_logloss: 0.207131\tvalid_1's auc: 0.685298\tvalid_1's binary_logloss: 0.212515\n",
      "[446]\ttraining's auc: 0.754771\ttraining's binary_logloss: 0.207106\tvalid_1's auc: 0.685348\tvalid_1's binary_logloss: 0.21251\n",
      "[447]\ttraining's auc: 0.754923\ttraining's binary_logloss: 0.207081\tvalid_1's auc: 0.685363\tvalid_1's binary_logloss: 0.212509\n",
      "[448]\ttraining's auc: 0.755088\ttraining's binary_logloss: 0.207053\tvalid_1's auc: 0.68537\tvalid_1's binary_logloss: 0.212508\n",
      "[449]\ttraining's auc: 0.755192\ttraining's binary_logloss: 0.207029\tvalid_1's auc: 0.685459\tvalid_1's binary_logloss: 0.212497\n",
      "[450]\ttraining's auc: 0.755292\ttraining's binary_logloss: 0.207003\tvalid_1's auc: 0.685556\tvalid_1's binary_logloss: 0.212485\n",
      "[451]\ttraining's auc: 0.75544\ttraining's binary_logloss: 0.206978\tvalid_1's auc: 0.685568\tvalid_1's binary_logloss: 0.212484\n",
      "[452]\ttraining's auc: 0.755586\ttraining's binary_logloss: 0.206956\tvalid_1's auc: 0.68554\tvalid_1's binary_logloss: 0.212486\n",
      "[453]\ttraining's auc: 0.755728\ttraining's binary_logloss: 0.206924\tvalid_1's auc: 0.685626\tvalid_1's binary_logloss: 0.212475\n",
      "[454]\ttraining's auc: 0.75586\ttraining's binary_logloss: 0.206894\tvalid_1's auc: 0.685727\tvalid_1's binary_logloss: 0.212461\n",
      "[455]\ttraining's auc: 0.756016\ttraining's binary_logloss: 0.20687\tvalid_1's auc: 0.68574\tvalid_1's binary_logloss: 0.212459\n",
      "[456]\ttraining's auc: 0.756122\ttraining's binary_logloss: 0.206847\tvalid_1's auc: 0.685719\tvalid_1's binary_logloss: 0.212461\n",
      "[457]\ttraining's auc: 0.756208\ttraining's binary_logloss: 0.206827\tvalid_1's auc: 0.68574\tvalid_1's binary_logloss: 0.212457\n",
      "[458]\ttraining's auc: 0.756312\ttraining's binary_logloss: 0.206809\tvalid_1's auc: 0.685736\tvalid_1's binary_logloss: 0.212458\n",
      "[459]\ttraining's auc: 0.75645\ttraining's binary_logloss: 0.206784\tvalid_1's auc: 0.685768\tvalid_1's binary_logloss: 0.212455\n",
      "[460]\ttraining's auc: 0.75663\ttraining's binary_logloss: 0.206756\tvalid_1's auc: 0.685811\tvalid_1's binary_logloss: 0.212447\n",
      "[461]\ttraining's auc: 0.756703\ttraining's binary_logloss: 0.206739\tvalid_1's auc: 0.685788\tvalid_1's binary_logloss: 0.212448\n",
      "[462]\ttraining's auc: 0.756879\ttraining's binary_logloss: 0.206714\tvalid_1's auc: 0.685865\tvalid_1's binary_logloss: 0.212438\n",
      "[463]\ttraining's auc: 0.757038\ttraining's binary_logloss: 0.206691\tvalid_1's auc: 0.685887\tvalid_1's binary_logloss: 0.212435\n",
      "[464]\ttraining's auc: 0.757199\ttraining's binary_logloss: 0.206667\tvalid_1's auc: 0.685868\tvalid_1's binary_logloss: 0.212436\n",
      "[465]\ttraining's auc: 0.757305\ttraining's binary_logloss: 0.206645\tvalid_1's auc: 0.685899\tvalid_1's binary_logloss: 0.212432\n",
      "[466]\ttraining's auc: 0.75738\ttraining's binary_logloss: 0.206634\tvalid_1's auc: 0.685896\tvalid_1's binary_logloss: 0.212433\n",
      "[467]\ttraining's auc: 0.757508\ttraining's binary_logloss: 0.206611\tvalid_1's auc: 0.685899\tvalid_1's binary_logloss: 0.212431\n",
      "[468]\ttraining's auc: 0.757624\ttraining's binary_logloss: 0.206594\tvalid_1's auc: 0.685849\tvalid_1's binary_logloss: 0.212434\n",
      "[469]\ttraining's auc: 0.757757\ttraining's binary_logloss: 0.206571\tvalid_1's auc: 0.68584\tvalid_1's binary_logloss: 0.212433\n",
      "[470]\ttraining's auc: 0.757884\ttraining's binary_logloss: 0.206549\tvalid_1's auc: 0.685839\tvalid_1's binary_logloss: 0.212434\n",
      "[471]\ttraining's auc: 0.758\ttraining's binary_logloss: 0.206524\tvalid_1's auc: 0.685939\tvalid_1's binary_logloss: 0.21242\n",
      "[472]\ttraining's auc: 0.758097\ttraining's binary_logloss: 0.2065\tvalid_1's auc: 0.686\tvalid_1's binary_logloss: 0.212411\n",
      "[473]\ttraining's auc: 0.758226\ttraining's binary_logloss: 0.206477\tvalid_1's auc: 0.686054\tvalid_1's binary_logloss: 0.212404\n",
      "[474]\ttraining's auc: 0.758367\ttraining's binary_logloss: 0.206454\tvalid_1's auc: 0.686043\tvalid_1's binary_logloss: 0.212405\n",
      "[475]\ttraining's auc: 0.758505\ttraining's binary_logloss: 0.206432\tvalid_1's auc: 0.686071\tvalid_1's binary_logloss: 0.212401\n",
      "[476]\ttraining's auc: 0.75864\ttraining's binary_logloss: 0.20641\tvalid_1's auc: 0.686114\tvalid_1's binary_logloss: 0.212398\n",
      "[477]\ttraining's auc: 0.758703\ttraining's binary_logloss: 0.206395\tvalid_1's auc: 0.68609\tvalid_1's binary_logloss: 0.212398\n",
      "[478]\ttraining's auc: 0.758758\ttraining's binary_logloss: 0.206383\tvalid_1's auc: 0.686082\tvalid_1's binary_logloss: 0.212398\n",
      "[479]\ttraining's auc: 0.758803\ttraining's binary_logloss: 0.206374\tvalid_1's auc: 0.686079\tvalid_1's binary_logloss: 0.212399\n",
      "[480]\ttraining's auc: 0.758948\ttraining's binary_logloss: 0.206352\tvalid_1's auc: 0.686092\tvalid_1's binary_logloss: 0.212399\n",
      "[481]\ttraining's auc: 0.759056\ttraining's binary_logloss: 0.206329\tvalid_1's auc: 0.686081\tvalid_1's binary_logloss: 0.212399\n",
      "[482]\ttraining's auc: 0.759167\ttraining's binary_logloss: 0.206305\tvalid_1's auc: 0.686134\tvalid_1's binary_logloss: 0.212393\n",
      "[483]\ttraining's auc: 0.759278\ttraining's binary_logloss: 0.206282\tvalid_1's auc: 0.686143\tvalid_1's binary_logloss: 0.212392\n",
      "[484]\ttraining's auc: 0.759398\ttraining's binary_logloss: 0.206259\tvalid_1's auc: 0.686132\tvalid_1's binary_logloss: 0.212391\n",
      "[485]\ttraining's auc: 0.759551\ttraining's binary_logloss: 0.206235\tvalid_1's auc: 0.686148\tvalid_1's binary_logloss: 0.212392\n",
      "[486]\ttraining's auc: 0.75965\ttraining's binary_logloss: 0.206214\tvalid_1's auc: 0.686143\tvalid_1's binary_logloss: 0.212388\n",
      "[487]\ttraining's auc: 0.759743\ttraining's binary_logloss: 0.206198\tvalid_1's auc: 0.686115\tvalid_1's binary_logloss: 0.21239\n",
      "[488]\ttraining's auc: 0.759914\ttraining's binary_logloss: 0.206177\tvalid_1's auc: 0.686109\tvalid_1's binary_logloss: 0.212391\n",
      "[489]\ttraining's auc: 0.760001\ttraining's binary_logloss: 0.206157\tvalid_1's auc: 0.686091\tvalid_1's binary_logloss: 0.212392\n",
      "[490]\ttraining's auc: 0.760083\ttraining's binary_logloss: 0.206137\tvalid_1's auc: 0.686167\tvalid_1's binary_logloss: 0.212381\n",
      "[491]\ttraining's auc: 0.760197\ttraining's binary_logloss: 0.206116\tvalid_1's auc: 0.686172\tvalid_1's binary_logloss: 0.21238\n",
      "[492]\ttraining's auc: 0.760293\ttraining's binary_logloss: 0.206098\tvalid_1's auc: 0.686173\tvalid_1's binary_logloss: 0.212382\n",
      "[493]\ttraining's auc: 0.760373\ttraining's binary_logloss: 0.20608\tvalid_1's auc: 0.686191\tvalid_1's binary_logloss: 0.212382\n",
      "[494]\ttraining's auc: 0.760474\ttraining's binary_logloss: 0.206059\tvalid_1's auc: 0.686174\tvalid_1's binary_logloss: 0.212383\n",
      "[495]\ttraining's auc: 0.760603\ttraining's binary_logloss: 0.206037\tvalid_1's auc: 0.686233\tvalid_1's binary_logloss: 0.212377\n",
      "[496]\ttraining's auc: 0.76073\ttraining's binary_logloss: 0.206016\tvalid_1's auc: 0.686234\tvalid_1's binary_logloss: 0.212376\n",
      "[497]\ttraining's auc: 0.76084\ttraining's binary_logloss: 0.205994\tvalid_1's auc: 0.686256\tvalid_1's binary_logloss: 0.212373\n",
      "[498]\ttraining's auc: 0.760959\ttraining's binary_logloss: 0.205975\tvalid_1's auc: 0.686242\tvalid_1's binary_logloss: 0.212373\n",
      "[499]\ttraining's auc: 0.761078\ttraining's binary_logloss: 0.205947\tvalid_1's auc: 0.686305\tvalid_1's binary_logloss: 0.212369\n",
      "[500]\ttraining's auc: 0.761116\ttraining's binary_logloss: 0.20594\tvalid_1's auc: 0.686318\tvalid_1's binary_logloss: 0.212367\n",
      "[501]\ttraining's auc: 0.761218\ttraining's binary_logloss: 0.205921\tvalid_1's auc: 0.686336\tvalid_1's binary_logloss: 0.212367\n",
      "[502]\ttraining's auc: 0.761312\ttraining's binary_logloss: 0.205898\tvalid_1's auc: 0.686341\tvalid_1's binary_logloss: 0.212363\n",
      "[503]\ttraining's auc: 0.761421\ttraining's binary_logloss: 0.205876\tvalid_1's auc: 0.686336\tvalid_1's binary_logloss: 0.212363\n",
      "[504]\ttraining's auc: 0.761554\ttraining's binary_logloss: 0.205851\tvalid_1's auc: 0.6863\tvalid_1's binary_logloss: 0.212368\n",
      "[505]\ttraining's auc: 0.76168\ttraining's binary_logloss: 0.205828\tvalid_1's auc: 0.686289\tvalid_1's binary_logloss: 0.212368\n",
      "[506]\ttraining's auc: 0.761812\ttraining's binary_logloss: 0.205807\tvalid_1's auc: 0.68632\tvalid_1's binary_logloss: 0.212366\n",
      "[507]\ttraining's auc: 0.761946\ttraining's binary_logloss: 0.205783\tvalid_1's auc: 0.686348\tvalid_1's binary_logloss: 0.21236\n",
      "[508]\ttraining's auc: 0.762082\ttraining's binary_logloss: 0.20576\tvalid_1's auc: 0.686385\tvalid_1's binary_logloss: 0.212357\n",
      "[509]\ttraining's auc: 0.762188\ttraining's binary_logloss: 0.205738\tvalid_1's auc: 0.686388\tvalid_1's binary_logloss: 0.212357\n",
      "[510]\ttraining's auc: 0.762291\ttraining's binary_logloss: 0.205717\tvalid_1's auc: 0.686388\tvalid_1's binary_logloss: 0.212355\n",
      "[511]\ttraining's auc: 0.762352\ttraining's binary_logloss: 0.205699\tvalid_1's auc: 0.686374\tvalid_1's binary_logloss: 0.212356\n",
      "[512]\ttraining's auc: 0.762441\ttraining's binary_logloss: 0.205677\tvalid_1's auc: 0.686411\tvalid_1's binary_logloss: 0.21235\n",
      "[513]\ttraining's auc: 0.76254\ttraining's binary_logloss: 0.205659\tvalid_1's auc: 0.686415\tvalid_1's binary_logloss: 0.212348\n",
      "[514]\ttraining's auc: 0.762666\ttraining's binary_logloss: 0.205641\tvalid_1's auc: 0.686402\tvalid_1's binary_logloss: 0.212347\n",
      "[515]\ttraining's auc: 0.762795\ttraining's binary_logloss: 0.205617\tvalid_1's auc: 0.686401\tvalid_1's binary_logloss: 0.212348\n",
      "[516]\ttraining's auc: 0.762903\ttraining's binary_logloss: 0.205593\tvalid_1's auc: 0.686423\tvalid_1's binary_logloss: 0.212346\n",
      "[517]\ttraining's auc: 0.763026\ttraining's binary_logloss: 0.205569\tvalid_1's auc: 0.686408\tvalid_1's binary_logloss: 0.212348\n",
      "[518]\ttraining's auc: 0.763131\ttraining's binary_logloss: 0.20555\tvalid_1's auc: 0.68641\tvalid_1's binary_logloss: 0.212349\n",
      "[519]\ttraining's auc: 0.763271\ttraining's binary_logloss: 0.205528\tvalid_1's auc: 0.686408\tvalid_1's binary_logloss: 0.212348\n",
      "[520]\ttraining's auc: 0.763399\ttraining's binary_logloss: 0.205508\tvalid_1's auc: 0.686431\tvalid_1's binary_logloss: 0.212342\n",
      "[521]\ttraining's auc: 0.763528\ttraining's binary_logloss: 0.205484\tvalid_1's auc: 0.686455\tvalid_1's binary_logloss: 0.212337\n",
      "[522]\ttraining's auc: 0.763651\ttraining's binary_logloss: 0.20546\tvalid_1's auc: 0.686468\tvalid_1's binary_logloss: 0.212335\n",
      "[523]\ttraining's auc: 0.763675\ttraining's binary_logloss: 0.205453\tvalid_1's auc: 0.686467\tvalid_1's binary_logloss: 0.212336\n",
      "[524]\ttraining's auc: 0.763784\ttraining's binary_logloss: 0.205432\tvalid_1's auc: 0.686477\tvalid_1's binary_logloss: 0.212336\n",
      "[525]\ttraining's auc: 0.763882\ttraining's binary_logloss: 0.205412\tvalid_1's auc: 0.686471\tvalid_1's binary_logloss: 0.212335\n",
      "[526]\ttraining's auc: 0.763991\ttraining's binary_logloss: 0.205394\tvalid_1's auc: 0.68647\tvalid_1's binary_logloss: 0.212335\n",
      "[527]\ttraining's auc: 0.764101\ttraining's binary_logloss: 0.205372\tvalid_1's auc: 0.686484\tvalid_1's binary_logloss: 0.212334\n",
      "[528]\ttraining's auc: 0.764209\ttraining's binary_logloss: 0.205349\tvalid_1's auc: 0.686532\tvalid_1's binary_logloss: 0.212329\n",
      "[529]\ttraining's auc: 0.764368\ttraining's binary_logloss: 0.205321\tvalid_1's auc: 0.686604\tvalid_1's binary_logloss: 0.212319\n",
      "[530]\ttraining's auc: 0.764525\ttraining's binary_logloss: 0.205295\tvalid_1's auc: 0.686666\tvalid_1's binary_logloss: 0.212312\n",
      "[531]\ttraining's auc: 0.764645\ttraining's binary_logloss: 0.205275\tvalid_1's auc: 0.68665\tvalid_1's binary_logloss: 0.212312\n",
      "[532]\ttraining's auc: 0.764769\ttraining's binary_logloss: 0.205253\tvalid_1's auc: 0.686666\tvalid_1's binary_logloss: 0.212309\n",
      "[533]\ttraining's auc: 0.764901\ttraining's binary_logloss: 0.205233\tvalid_1's auc: 0.686664\tvalid_1's binary_logloss: 0.21231\n",
      "[534]\ttraining's auc: 0.764967\ttraining's binary_logloss: 0.205219\tvalid_1's auc: 0.686709\tvalid_1's binary_logloss: 0.212305\n",
      "[535]\ttraining's auc: 0.765117\ttraining's binary_logloss: 0.205193\tvalid_1's auc: 0.686742\tvalid_1's binary_logloss: 0.212302\n",
      "[536]\ttraining's auc: 0.765247\ttraining's binary_logloss: 0.205169\tvalid_1's auc: 0.686715\tvalid_1's binary_logloss: 0.212303\n",
      "[537]\ttraining's auc: 0.76539\ttraining's binary_logloss: 0.205146\tvalid_1's auc: 0.686689\tvalid_1's binary_logloss: 0.212305\n",
      "[538]\ttraining's auc: 0.765538\ttraining's binary_logloss: 0.205122\tvalid_1's auc: 0.686723\tvalid_1's binary_logloss: 0.212302\n",
      "[539]\ttraining's auc: 0.765636\ttraining's binary_logloss: 0.205098\tvalid_1's auc: 0.686758\tvalid_1's binary_logloss: 0.212299\n",
      "[540]\ttraining's auc: 0.765727\ttraining's binary_logloss: 0.205076\tvalid_1's auc: 0.686769\tvalid_1's binary_logloss: 0.212297\n",
      "[541]\ttraining's auc: 0.765788\ttraining's binary_logloss: 0.205056\tvalid_1's auc: 0.686808\tvalid_1's binary_logloss: 0.212289\n",
      "[542]\ttraining's auc: 0.765855\ttraining's binary_logloss: 0.205036\tvalid_1's auc: 0.686801\tvalid_1's binary_logloss: 0.212286\n",
      "[543]\ttraining's auc: 0.765992\ttraining's binary_logloss: 0.205013\tvalid_1's auc: 0.686893\tvalid_1's binary_logloss: 0.212278\n",
      "[544]\ttraining's auc: 0.766093\ttraining's binary_logloss: 0.204992\tvalid_1's auc: 0.686907\tvalid_1's binary_logloss: 0.212274\n",
      "[545]\ttraining's auc: 0.766212\ttraining's binary_logloss: 0.204969\tvalid_1's auc: 0.686913\tvalid_1's binary_logloss: 0.212275\n",
      "[546]\ttraining's auc: 0.766345\ttraining's binary_logloss: 0.204946\tvalid_1's auc: 0.686916\tvalid_1's binary_logloss: 0.212275\n",
      "[547]\ttraining's auc: 0.766469\ttraining's binary_logloss: 0.204925\tvalid_1's auc: 0.686918\tvalid_1's binary_logloss: 0.212274\n",
      "[548]\ttraining's auc: 0.766631\ttraining's binary_logloss: 0.204902\tvalid_1's auc: 0.686943\tvalid_1's binary_logloss: 0.21227\n",
      "[549]\ttraining's auc: 0.766787\ttraining's binary_logloss: 0.204877\tvalid_1's auc: 0.686959\tvalid_1's binary_logloss: 0.21227\n",
      "[550]\ttraining's auc: 0.766918\ttraining's binary_logloss: 0.204853\tvalid_1's auc: 0.686949\tvalid_1's binary_logloss: 0.212267\n",
      "[551]\ttraining's auc: 0.76704\ttraining's binary_logloss: 0.204828\tvalid_1's auc: 0.686975\tvalid_1's binary_logloss: 0.212264\n",
      "[552]\ttraining's auc: 0.767133\ttraining's binary_logloss: 0.204808\tvalid_1's auc: 0.686974\tvalid_1's binary_logloss: 0.212264\n",
      "[553]\ttraining's auc: 0.767278\ttraining's binary_logloss: 0.204784\tvalid_1's auc: 0.686965\tvalid_1's binary_logloss: 0.212265\n",
      "[554]\ttraining's auc: 0.767378\ttraining's binary_logloss: 0.204763\tvalid_1's auc: 0.686969\tvalid_1's binary_logloss: 0.212265\n",
      "[555]\ttraining's auc: 0.767509\ttraining's binary_logloss: 0.204741\tvalid_1's auc: 0.687001\tvalid_1's binary_logloss: 0.212263\n",
      "[556]\ttraining's auc: 0.767638\ttraining's binary_logloss: 0.20472\tvalid_1's auc: 0.687\tvalid_1's binary_logloss: 0.212264\n",
      "[557]\ttraining's auc: 0.76773\ttraining's binary_logloss: 0.2047\tvalid_1's auc: 0.687014\tvalid_1's binary_logloss: 0.212259\n",
      "[558]\ttraining's auc: 0.767861\ttraining's binary_logloss: 0.204682\tvalid_1's auc: 0.686986\tvalid_1's binary_logloss: 0.212261\n",
      "[559]\ttraining's auc: 0.767971\ttraining's binary_logloss: 0.204662\tvalid_1's auc: 0.686986\tvalid_1's binary_logloss: 0.21226\n",
      "[560]\ttraining's auc: 0.767997\ttraining's binary_logloss: 0.204652\tvalid_1's auc: 0.686994\tvalid_1's binary_logloss: 0.212258\n",
      "[561]\ttraining's auc: 0.768118\ttraining's binary_logloss: 0.204629\tvalid_1's auc: 0.68702\tvalid_1's binary_logloss: 0.212255\n",
      "[562]\ttraining's auc: 0.768232\ttraining's binary_logloss: 0.204608\tvalid_1's auc: 0.687049\tvalid_1's binary_logloss: 0.212253\n",
      "[563]\ttraining's auc: 0.768379\ttraining's binary_logloss: 0.204585\tvalid_1's auc: 0.687051\tvalid_1's binary_logloss: 0.212255\n",
      "[564]\ttraining's auc: 0.768516\ttraining's binary_logloss: 0.204561\tvalid_1's auc: 0.687061\tvalid_1's binary_logloss: 0.212253\n",
      "[565]\ttraining's auc: 0.768648\ttraining's binary_logloss: 0.204537\tvalid_1's auc: 0.687022\tvalid_1's binary_logloss: 0.212259\n",
      "[566]\ttraining's auc: 0.768795\ttraining's binary_logloss: 0.204514\tvalid_1's auc: 0.68699\tvalid_1's binary_logloss: 0.212263\n",
      "[567]\ttraining's auc: 0.76895\ttraining's binary_logloss: 0.204489\tvalid_1's auc: 0.68695\tvalid_1's binary_logloss: 0.212267\n",
      "[568]\ttraining's auc: 0.769043\ttraining's binary_logloss: 0.204468\tvalid_1's auc: 0.687007\tvalid_1's binary_logloss: 0.212264\n",
      "[569]\ttraining's auc: 0.769132\ttraining's binary_logloss: 0.204447\tvalid_1's auc: 0.687046\tvalid_1's binary_logloss: 0.212259\n",
      "[570]\ttraining's auc: 0.76924\ttraining's binary_logloss: 0.204425\tvalid_1's auc: 0.687069\tvalid_1's binary_logloss: 0.212256\n",
      "[571]\ttraining's auc: 0.769364\ttraining's binary_logloss: 0.204406\tvalid_1's auc: 0.687086\tvalid_1's binary_logloss: 0.212255\n",
      "[572]\ttraining's auc: 0.7695\ttraining's binary_logloss: 0.204383\tvalid_1's auc: 0.687114\tvalid_1's binary_logloss: 0.212254\n",
      "[573]\ttraining's auc: 0.769641\ttraining's binary_logloss: 0.204361\tvalid_1's auc: 0.687119\tvalid_1's binary_logloss: 0.212253\n",
      "[574]\ttraining's auc: 0.769758\ttraining's binary_logloss: 0.204342\tvalid_1's auc: 0.687129\tvalid_1's binary_logloss: 0.212252\n",
      "[575]\ttraining's auc: 0.769853\ttraining's binary_logloss: 0.204318\tvalid_1's auc: 0.687182\tvalid_1's binary_logloss: 0.212244\n",
      "[576]\ttraining's auc: 0.769967\ttraining's binary_logloss: 0.204295\tvalid_1's auc: 0.687222\tvalid_1's binary_logloss: 0.212239\n",
      "[577]\ttraining's auc: 0.770108\ttraining's binary_logloss: 0.20427\tvalid_1's auc: 0.687203\tvalid_1's binary_logloss: 0.212239\n",
      "[578]\ttraining's auc: 0.770238\ttraining's binary_logloss: 0.204247\tvalid_1's auc: 0.687227\tvalid_1's binary_logloss: 0.212235\n",
      "[579]\ttraining's auc: 0.770329\ttraining's binary_logloss: 0.204231\tvalid_1's auc: 0.687209\tvalid_1's binary_logloss: 0.212237\n",
      "[580]\ttraining's auc: 0.77047\ttraining's binary_logloss: 0.204208\tvalid_1's auc: 0.687159\tvalid_1's binary_logloss: 0.212244\n",
      "[581]\ttraining's auc: 0.770567\ttraining's binary_logloss: 0.204185\tvalid_1's auc: 0.68718\tvalid_1's binary_logloss: 0.21224\n",
      "[582]\ttraining's auc: 0.770717\ttraining's binary_logloss: 0.204161\tvalid_1's auc: 0.687178\tvalid_1's binary_logloss: 0.21224\n",
      "[583]\ttraining's auc: 0.770808\ttraining's binary_logloss: 0.204142\tvalid_1's auc: 0.687169\tvalid_1's binary_logloss: 0.212239\n",
      "[584]\ttraining's auc: 0.770921\ttraining's binary_logloss: 0.204124\tvalid_1's auc: 0.687169\tvalid_1's binary_logloss: 0.21224\n",
      "[585]\ttraining's auc: 0.771015\ttraining's binary_logloss: 0.204101\tvalid_1's auc: 0.687166\tvalid_1's binary_logloss: 0.21224\n",
      "[586]\ttraining's auc: 0.771121\ttraining's binary_logloss: 0.204078\tvalid_1's auc: 0.687145\tvalid_1's binary_logloss: 0.212239\n",
      "[587]\ttraining's auc: 0.77124\ttraining's binary_logloss: 0.204056\tvalid_1's auc: 0.687167\tvalid_1's binary_logloss: 0.212237\n",
      "[588]\ttraining's auc: 0.771356\ttraining's binary_logloss: 0.204037\tvalid_1's auc: 0.68716\tvalid_1's binary_logloss: 0.212238\n",
      "[589]\ttraining's auc: 0.771485\ttraining's binary_logloss: 0.204015\tvalid_1's auc: 0.687158\tvalid_1's binary_logloss: 0.212237\n",
      "[590]\ttraining's auc: 0.771577\ttraining's binary_logloss: 0.204001\tvalid_1's auc: 0.687151\tvalid_1's binary_logloss: 0.212239\n",
      "[591]\ttraining's auc: 0.771724\ttraining's binary_logloss: 0.203979\tvalid_1's auc: 0.687183\tvalid_1's binary_logloss: 0.212235\n",
      "[592]\ttraining's auc: 0.771878\ttraining's binary_logloss: 0.203956\tvalid_1's auc: 0.687167\tvalid_1's binary_logloss: 0.212236\n",
      "[593]\ttraining's auc: 0.771996\ttraining's binary_logloss: 0.20393\tvalid_1's auc: 0.687201\tvalid_1's binary_logloss: 0.212231\n",
      "[594]\ttraining's auc: 0.77208\ttraining's binary_logloss: 0.20391\tvalid_1's auc: 0.687228\tvalid_1's binary_logloss: 0.21223\n",
      "[595]\ttraining's auc: 0.772119\ttraining's binary_logloss: 0.203901\tvalid_1's auc: 0.687231\tvalid_1's binary_logloss: 0.21223\n",
      "[596]\ttraining's auc: 0.772189\ttraining's binary_logloss: 0.203889\tvalid_1's auc: 0.68725\tvalid_1's binary_logloss: 0.212229\n",
      "[597]\ttraining's auc: 0.772316\ttraining's binary_logloss: 0.203868\tvalid_1's auc: 0.687288\tvalid_1's binary_logloss: 0.212227\n",
      "[598]\ttraining's auc: 0.772425\ttraining's binary_logloss: 0.203848\tvalid_1's auc: 0.687297\tvalid_1's binary_logloss: 0.212226\n",
      "[599]\ttraining's auc: 0.772571\ttraining's binary_logloss: 0.203822\tvalid_1's auc: 0.687328\tvalid_1's binary_logloss: 0.212221\n",
      "[600]\ttraining's auc: 0.772731\ttraining's binary_logloss: 0.203798\tvalid_1's auc: 0.687375\tvalid_1's binary_logloss: 0.212216\n",
      "[601]\ttraining's auc: 0.772814\ttraining's binary_logloss: 0.203782\tvalid_1's auc: 0.687395\tvalid_1's binary_logloss: 0.212216\n",
      "[602]\ttraining's auc: 0.772896\ttraining's binary_logloss: 0.203761\tvalid_1's auc: 0.687402\tvalid_1's binary_logloss: 0.212212\n",
      "[603]\ttraining's auc: 0.773041\ttraining's binary_logloss: 0.203735\tvalid_1's auc: 0.687417\tvalid_1's binary_logloss: 0.212212\n",
      "[604]\ttraining's auc: 0.773167\ttraining's binary_logloss: 0.203711\tvalid_1's auc: 0.687395\tvalid_1's binary_logloss: 0.212214\n",
      "[605]\ttraining's auc: 0.773213\ttraining's binary_logloss: 0.2037\tvalid_1's auc: 0.687382\tvalid_1's binary_logloss: 0.212217\n",
      "[606]\ttraining's auc: 0.773363\ttraining's binary_logloss: 0.203677\tvalid_1's auc: 0.687389\tvalid_1's binary_logloss: 0.212215\n",
      "[607]\ttraining's auc: 0.773498\ttraining's binary_logloss: 0.203654\tvalid_1's auc: 0.687361\tvalid_1's binary_logloss: 0.212219\n",
      "[608]\ttraining's auc: 0.773627\ttraining's binary_logloss: 0.203633\tvalid_1's auc: 0.687362\tvalid_1's binary_logloss: 0.212222\n",
      "[609]\ttraining's auc: 0.773789\ttraining's binary_logloss: 0.203607\tvalid_1's auc: 0.687375\tvalid_1's binary_logloss: 0.212221\n",
      "[610]\ttraining's auc: 0.773922\ttraining's binary_logloss: 0.203583\tvalid_1's auc: 0.687414\tvalid_1's binary_logloss: 0.212215\n",
      "[611]\ttraining's auc: 0.773991\ttraining's binary_logloss: 0.203568\tvalid_1's auc: 0.687417\tvalid_1's binary_logloss: 0.212215\n",
      "[612]\ttraining's auc: 0.774061\ttraining's binary_logloss: 0.203551\tvalid_1's auc: 0.687414\tvalid_1's binary_logloss: 0.212215\n",
      "[613]\ttraining's auc: 0.774196\ttraining's binary_logloss: 0.20353\tvalid_1's auc: 0.6874\tvalid_1's binary_logloss: 0.212215\n",
      "[614]\ttraining's auc: 0.774328\ttraining's binary_logloss: 0.203512\tvalid_1's auc: 0.68738\tvalid_1's binary_logloss: 0.212216\n",
      "[615]\ttraining's auc: 0.774412\ttraining's binary_logloss: 0.203488\tvalid_1's auc: 0.687391\tvalid_1's binary_logloss: 0.212214\n",
      "[616]\ttraining's auc: 0.774496\ttraining's binary_logloss: 0.203464\tvalid_1's auc: 0.687382\tvalid_1's binary_logloss: 0.212217\n",
      "[617]\ttraining's auc: 0.774617\ttraining's binary_logloss: 0.203444\tvalid_1's auc: 0.68737\tvalid_1's binary_logloss: 0.212219\n",
      "[618]\ttraining's auc: 0.774703\ttraining's binary_logloss: 0.203424\tvalid_1's auc: 0.687354\tvalid_1's binary_logloss: 0.212221\n",
      "[619]\ttraining's auc: 0.77474\ttraining's binary_logloss: 0.203414\tvalid_1's auc: 0.687352\tvalid_1's binary_logloss: 0.212222\n",
      "[620]\ttraining's auc: 0.774845\ttraining's binary_logloss: 0.203393\tvalid_1's auc: 0.687339\tvalid_1's binary_logloss: 0.212225\n",
      "[621]\ttraining's auc: 0.774901\ttraining's binary_logloss: 0.203376\tvalid_1's auc: 0.687321\tvalid_1's binary_logloss: 0.212228\n",
      "[622]\ttraining's auc: 0.775011\ttraining's binary_logloss: 0.203356\tvalid_1's auc: 0.6873\tvalid_1's binary_logloss: 0.212231\n",
      "[623]\ttraining's auc: 0.775134\ttraining's binary_logloss: 0.203334\tvalid_1's auc: 0.687265\tvalid_1's binary_logloss: 0.212235\n",
      "[624]\ttraining's auc: 0.77526\ttraining's binary_logloss: 0.203312\tvalid_1's auc: 0.687286\tvalid_1's binary_logloss: 0.212231\n",
      "[625]\ttraining's auc: 0.775386\ttraining's binary_logloss: 0.20329\tvalid_1's auc: 0.687257\tvalid_1's binary_logloss: 0.212234\n",
      "[626]\ttraining's auc: 0.775499\ttraining's binary_logloss: 0.203264\tvalid_1's auc: 0.68732\tvalid_1's binary_logloss: 0.212225\n",
      "[627]\ttraining's auc: 0.775597\ttraining's binary_logloss: 0.203242\tvalid_1's auc: 0.687329\tvalid_1's binary_logloss: 0.212224\n",
      "[628]\ttraining's auc: 0.775708\ttraining's binary_logloss: 0.203221\tvalid_1's auc: 0.687356\tvalid_1's binary_logloss: 0.212219\n",
      "[629]\ttraining's auc: 0.775828\ttraining's binary_logloss: 0.203199\tvalid_1's auc: 0.687327\tvalid_1's binary_logloss: 0.212225\n",
      "[630]\ttraining's auc: 0.775954\ttraining's binary_logloss: 0.203176\tvalid_1's auc: 0.687332\tvalid_1's binary_logloss: 0.212223\n",
      "[631]\ttraining's auc: 0.776048\ttraining's binary_logloss: 0.20316\tvalid_1's auc: 0.687342\tvalid_1's binary_logloss: 0.212221\n",
      "[632]\ttraining's auc: 0.776137\ttraining's binary_logloss: 0.203141\tvalid_1's auc: 0.687356\tvalid_1's binary_logloss: 0.212218\n",
      "[633]\ttraining's auc: 0.776204\ttraining's binary_logloss: 0.203123\tvalid_1's auc: 0.687332\tvalid_1's binary_logloss: 0.212219\n",
      "[634]\ttraining's auc: 0.776324\ttraining's binary_logloss: 0.203101\tvalid_1's auc: 0.68732\tvalid_1's binary_logloss: 0.212217\n",
      "[635]\ttraining's auc: 0.776423\ttraining's binary_logloss: 0.203082\tvalid_1's auc: 0.687342\tvalid_1's binary_logloss: 0.212215\n",
      "[636]\ttraining's auc: 0.77655\ttraining's binary_logloss: 0.203061\tvalid_1's auc: 0.687327\tvalid_1's binary_logloss: 0.212216\n",
      "[637]\ttraining's auc: 0.776719\ttraining's binary_logloss: 0.203037\tvalid_1's auc: 0.687339\tvalid_1's binary_logloss: 0.212218\n",
      "[638]\ttraining's auc: 0.776833\ttraining's binary_logloss: 0.203018\tvalid_1's auc: 0.687322\tvalid_1's binary_logloss: 0.212222\n",
      "[639]\ttraining's auc: 0.776923\ttraining's binary_logloss: 0.203\tvalid_1's auc: 0.687302\tvalid_1's binary_logloss: 0.212225\n",
      "[640]\ttraining's auc: 0.777028\ttraining's binary_logloss: 0.202982\tvalid_1's auc: 0.687299\tvalid_1's binary_logloss: 0.212223\n",
      "[641]\ttraining's auc: 0.777178\ttraining's binary_logloss: 0.20296\tvalid_1's auc: 0.68732\tvalid_1's binary_logloss: 0.212221\n",
      "[642]\ttraining's auc: 0.777315\ttraining's binary_logloss: 0.202936\tvalid_1's auc: 0.687303\tvalid_1's binary_logloss: 0.212222\n",
      "[643]\ttraining's auc: 0.777488\ttraining's binary_logloss: 0.20291\tvalid_1's auc: 0.687274\tvalid_1's binary_logloss: 0.212227\n",
      "[644]\ttraining's auc: 0.777635\ttraining's binary_logloss: 0.202885\tvalid_1's auc: 0.687194\tvalid_1's binary_logloss: 0.212236\n",
      "[645]\ttraining's auc: 0.777755\ttraining's binary_logloss: 0.202864\tvalid_1's auc: 0.68722\tvalid_1's binary_logloss: 0.212233\n",
      "[646]\ttraining's auc: 0.777868\ttraining's binary_logloss: 0.202842\tvalid_1's auc: 0.687252\tvalid_1's binary_logloss: 0.212229\n",
      "[647]\ttraining's auc: 0.778008\ttraining's binary_logloss: 0.202816\tvalid_1's auc: 0.687238\tvalid_1's binary_logloss: 0.212228\n",
      "[648]\ttraining's auc: 0.778121\ttraining's binary_logloss: 0.202794\tvalid_1's auc: 0.687209\tvalid_1's binary_logloss: 0.212232\n",
      "[649]\ttraining's auc: 0.778203\ttraining's binary_logloss: 0.202778\tvalid_1's auc: 0.68719\tvalid_1's binary_logloss: 0.212236\n",
      "[650]\ttraining's auc: 0.77822\ttraining's binary_logloss: 0.202774\tvalid_1's auc: 0.687186\tvalid_1's binary_logloss: 0.212238\n",
      "[651]\ttraining's auc: 0.778316\ttraining's binary_logloss: 0.202755\tvalid_1's auc: 0.687146\tvalid_1's binary_logloss: 0.212242\n",
      "[652]\ttraining's auc: 0.778404\ttraining's binary_logloss: 0.202735\tvalid_1's auc: 0.687142\tvalid_1's binary_logloss: 0.212243\n",
      "[653]\ttraining's auc: 0.778545\ttraining's binary_logloss: 0.202713\tvalid_1's auc: 0.687116\tvalid_1's binary_logloss: 0.212243\n",
      "[654]\ttraining's auc: 0.778635\ttraining's binary_logloss: 0.202693\tvalid_1's auc: 0.687075\tvalid_1's binary_logloss: 0.212246\n",
      "[655]\ttraining's auc: 0.778725\ttraining's binary_logloss: 0.202674\tvalid_1's auc: 0.687095\tvalid_1's binary_logloss: 0.212243\n",
      "[656]\ttraining's auc: 0.778774\ttraining's binary_logloss: 0.202658\tvalid_1's auc: 0.687114\tvalid_1's binary_logloss: 0.212242\n",
      "[657]\ttraining's auc: 0.778877\ttraining's binary_logloss: 0.202634\tvalid_1's auc: 0.687176\tvalid_1's binary_logloss: 0.212235\n",
      "[658]\ttraining's auc: 0.778995\ttraining's binary_logloss: 0.202612\tvalid_1's auc: 0.687148\tvalid_1's binary_logloss: 0.212238\n",
      "[659]\ttraining's auc: 0.779153\ttraining's binary_logloss: 0.202588\tvalid_1's auc: 0.687085\tvalid_1's binary_logloss: 0.212246\n",
      "[660]\ttraining's auc: 0.779293\ttraining's binary_logloss: 0.202563\tvalid_1's auc: 0.687016\tvalid_1's binary_logloss: 0.212252\n",
      "[661]\ttraining's auc: 0.779424\ttraining's binary_logloss: 0.202542\tvalid_1's auc: 0.687012\tvalid_1's binary_logloss: 0.212253\n",
      "[662]\ttraining's auc: 0.779472\ttraining's binary_logloss: 0.202524\tvalid_1's auc: 0.68704\tvalid_1's binary_logloss: 0.212249\n",
      "[663]\ttraining's auc: 0.779533\ttraining's binary_logloss: 0.202507\tvalid_1's auc: 0.687034\tvalid_1's binary_logloss: 0.21225\n",
      "[664]\ttraining's auc: 0.779585\ttraining's binary_logloss: 0.202488\tvalid_1's auc: 0.68706\tvalid_1's binary_logloss: 0.212247\n",
      "[665]\ttraining's auc: 0.779705\ttraining's binary_logloss: 0.202466\tvalid_1's auc: 0.687068\tvalid_1's binary_logloss: 0.212245\n",
      "[666]\ttraining's auc: 0.779801\ttraining's binary_logloss: 0.202445\tvalid_1's auc: 0.687103\tvalid_1's binary_logloss: 0.212241\n",
      "[667]\ttraining's auc: 0.779887\ttraining's binary_logloss: 0.202425\tvalid_1's auc: 0.68709\tvalid_1's binary_logloss: 0.212241\n",
      "[668]\ttraining's auc: 0.779997\ttraining's binary_logloss: 0.202405\tvalid_1's auc: 0.687107\tvalid_1's binary_logloss: 0.212239\n",
      "[669]\ttraining's auc: 0.780076\ttraining's binary_logloss: 0.202382\tvalid_1's auc: 0.687089\tvalid_1's binary_logloss: 0.212241\n",
      "[670]\ttraining's auc: 0.7802\ttraining's binary_logloss: 0.20236\tvalid_1's auc: 0.687063\tvalid_1's binary_logloss: 0.212244\n",
      "[671]\ttraining's auc: 0.78032\ttraining's binary_logloss: 0.202335\tvalid_1's auc: 0.687069\tvalid_1's binary_logloss: 0.212248\n",
      "[672]\ttraining's auc: 0.780417\ttraining's binary_logloss: 0.202313\tvalid_1's auc: 0.687096\tvalid_1's binary_logloss: 0.212244\n",
      "[673]\ttraining's auc: 0.780528\ttraining's binary_logloss: 0.202291\tvalid_1's auc: 0.687065\tvalid_1's binary_logloss: 0.212248\n",
      "[674]\ttraining's auc: 0.780639\ttraining's binary_logloss: 0.202268\tvalid_1's auc: 0.687048\tvalid_1's binary_logloss: 0.212248\n",
      "[675]\ttraining's auc: 0.780748\ttraining's binary_logloss: 0.202248\tvalid_1's auc: 0.687018\tvalid_1's binary_logloss: 0.21225\n",
      "[676]\ttraining's auc: 0.780877\ttraining's binary_logloss: 0.202225\tvalid_1's auc: 0.687072\tvalid_1's binary_logloss: 0.212244\n",
      "[677]\ttraining's auc: 0.780987\ttraining's binary_logloss: 0.202204\tvalid_1's auc: 0.687108\tvalid_1's binary_logloss: 0.212237\n",
      "[678]\ttraining's auc: 0.781126\ttraining's binary_logloss: 0.202183\tvalid_1's auc: 0.68709\tvalid_1's binary_logloss: 0.212237\n",
      "[679]\ttraining's auc: 0.781169\ttraining's binary_logloss: 0.202174\tvalid_1's auc: 0.687089\tvalid_1's binary_logloss: 0.212239\n",
      "[680]\ttraining's auc: 0.781223\ttraining's binary_logloss: 0.202162\tvalid_1's auc: 0.687069\tvalid_1's binary_logloss: 0.212242\n",
      "[681]\ttraining's auc: 0.781303\ttraining's binary_logloss: 0.202147\tvalid_1's auc: 0.687029\tvalid_1's binary_logloss: 0.212246\n",
      "[682]\ttraining's auc: 0.781439\ttraining's binary_logloss: 0.202124\tvalid_1's auc: 0.686992\tvalid_1's binary_logloss: 0.212251\n",
      "[683]\ttraining's auc: 0.781555\ttraining's binary_logloss: 0.202101\tvalid_1's auc: 0.686998\tvalid_1's binary_logloss: 0.212254\n",
      "[684]\ttraining's auc: 0.781685\ttraining's binary_logloss: 0.20208\tvalid_1's auc: 0.687024\tvalid_1's binary_logloss: 0.212253\n",
      "[685]\ttraining's auc: 0.781786\ttraining's binary_logloss: 0.202059\tvalid_1's auc: 0.687025\tvalid_1's binary_logloss: 0.212252\n",
      "[686]\ttraining's auc: 0.781842\ttraining's binary_logloss: 0.202049\tvalid_1's auc: 0.687036\tvalid_1's binary_logloss: 0.21225\n",
      "[687]\ttraining's auc: 0.781976\ttraining's binary_logloss: 0.202027\tvalid_1's auc: 0.686985\tvalid_1's binary_logloss: 0.212254\n",
      "[688]\ttraining's auc: 0.782098\ttraining's binary_logloss: 0.202006\tvalid_1's auc: 0.686945\tvalid_1's binary_logloss: 0.212257\n",
      "[689]\ttraining's auc: 0.782185\ttraining's binary_logloss: 0.201983\tvalid_1's auc: 0.686915\tvalid_1's binary_logloss: 0.212261\n",
      "[690]\ttraining's auc: 0.782292\ttraining's binary_logloss: 0.20196\tvalid_1's auc: 0.686926\tvalid_1's binary_logloss: 0.21226\n",
      "[691]\ttraining's auc: 0.782338\ttraining's binary_logloss: 0.201948\tvalid_1's auc: 0.686893\tvalid_1's binary_logloss: 0.212261\n",
      "[692]\ttraining's auc: 0.782463\ttraining's binary_logloss: 0.201928\tvalid_1's auc: 0.686899\tvalid_1's binary_logloss: 0.212259\n",
      "[693]\ttraining's auc: 0.782568\ttraining's binary_logloss: 0.201908\tvalid_1's auc: 0.686857\tvalid_1's binary_logloss: 0.212264\n",
      "[694]\ttraining's auc: 0.782697\ttraining's binary_logloss: 0.201885\tvalid_1's auc: 0.686857\tvalid_1's binary_logloss: 0.212264\n",
      "[695]\ttraining's auc: 0.782812\ttraining's binary_logloss: 0.201864\tvalid_1's auc: 0.686853\tvalid_1's binary_logloss: 0.212266\n",
      "[696]\ttraining's auc: 0.782908\ttraining's binary_logloss: 0.201845\tvalid_1's auc: 0.686863\tvalid_1's binary_logloss: 0.212263\n",
      "[697]\ttraining's auc: 0.783024\ttraining's binary_logloss: 0.201822\tvalid_1's auc: 0.686854\tvalid_1's binary_logloss: 0.212264\n",
      "[698]\ttraining's auc: 0.783119\ttraining's binary_logloss: 0.201802\tvalid_1's auc: 0.686879\tvalid_1's binary_logloss: 0.212261\n",
      "[699]\ttraining's auc: 0.7832\ttraining's binary_logloss: 0.201784\tvalid_1's auc: 0.686891\tvalid_1's binary_logloss: 0.212263\n",
      "[700]\ttraining's auc: 0.783289\ttraining's binary_logloss: 0.201768\tvalid_1's auc: 0.686904\tvalid_1's binary_logloss: 0.212262\n",
      "[701]\ttraining's auc: 0.783374\ttraining's binary_logloss: 0.201747\tvalid_1's auc: 0.686876\tvalid_1's binary_logloss: 0.212265\n",
      "[702]\ttraining's auc: 0.783488\ttraining's binary_logloss: 0.201725\tvalid_1's auc: 0.686882\tvalid_1's binary_logloss: 0.212263\n",
      "[703]\ttraining's auc: 0.783597\ttraining's binary_logloss: 0.201706\tvalid_1's auc: 0.68692\tvalid_1's binary_logloss: 0.212259\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's auc: 0.773041\ttraining's binary_logloss: 0.203735\tvalid_1's auc: 0.687417\tvalid_1's binary_logloss: 0.212212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.8, learning_rate=0.015, max_depth=10,\n",
       "               min_child_samples=300, min_split_gain=0.1, n_estimators=2000,\n",
       "               num_leaves=51, objective='binary', reg_alpha=0.12,\n",
       "               reg_lambda=0.28, subsample=0.75, subsample_freq=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用LightGBM模型\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(\n",
    "    num_leaves=51,\n",
    "    max_depth=10,\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    learning_rate=0.015,\n",
    "    n_estimators=2000,\n",
    "    subsample=0.75,\n",
    "    subsample_freq=2,\n",
    "    reg_lambda=0.28,\n",
    "    reg_alpha=0.12,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_samples=300,\n",
    "    min_split_gain=0.1\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_metric='auc', \n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oNFJNiuuWI1"
   },
   "source": [
    "### 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQX6Zqpitzua"
   },
   "outputs": [],
   "source": [
    "prob = model.predict_proba(test_data)\n",
    "df_test1['prob'] = pd.Series(prob[:,1])\n",
    "# df_test1.drop(['origin'], axis=1, inplace=True)\n",
    "df_test1.to_csv('prediction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "026nJmVREn10"
   },
   "source": [
    "- xgbboost 目前测试集最高得分0.6774169，prediction1.csv\n",
    "- lightgbm 目前测试集最高得分0.6827759，prediction2.csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWgY4b03rd18y+QHWbMziC",
   "collapsed_sections": [],
   "mount_file_id": "1BVsSQnq5YGCj9zTgUe8kJD8ldAsWO4AA",
   "name": "Tmall_Repeat_Buyers_boosting.ipynb",
   "provenance": [
    {
     "file_id": "12I0jTP81uXJo9u59HumxxukRzAV2Y34b",
     "timestamp": 1589730404670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
